---
title: 'Dissertation Analysis: Incorrect Items Collected'
author: "Jamiahus Walton"
date: "5/7/2019"
output: html_document
editor_options:
  chunk_output_type: inline
csl: apa.csl
bibliography: bibliography.bib
params:
  dependent_response_name_WithSpace: "Incorrect Items"
  dependent_response_name_NoSpace: "Incorrect Items"
  dependent_response_team: "II_team"
  dependent_response_ind: "II_ind"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Tips for formatting in RMarkdown
# Link: https://monashbioinformaticsplatform.github.io/2017-11-16-open-science-training/topics/rmarkdown.html

# Equations
# Link: https://www.calvin.edu/~rpruim/courses/s341/S17/from-class/MathinRmd.html

# Create awesome HTML table with knitr::kableand kableExtra
# LinkL https://haozhu233.github.io/kableExtra/awesome_table_in_html.html

# Examples of how to use the ggrepel package
# Link: https://cran.r-project.org/web/packages/ggrepel/vignettes/ggrepel.html#examples

# Packages for data analysis
library(tidyverse)
library(lme4)
library(lmerTest)
library(emmeans)
library(svMisc)
library(MuMIn)
library(modelr)
library(sjstats)
library(robustlmm)
library(ggrepel)
library(knitr)
library(kableExtra)

# Functions used in documents ----
remove_measures_with_given_value <- function(data_set, col_name, value){
  rows_to_move <- which(as.vector(data_set[,col_name]) == value) 
  
  return(data_set[-rows_to_move,])
}

# Factor columns that need it.
re_factor_columns <- function(userData, columnNames){
  factorData <- userData
  for(column in columnNames){
    print(column)
    factorData[,column] <- factor(factorData[,column])
  }
  return(factorData)
}

# Model the data for the team level analysis ----
model_data_Target_Session <- function(df, dependent, model.type, is.team, is.robust){
  
  if(is.team){
    if(model.type == "null" && !is.robust){
      lmer(data = df, as.formula(paste(dependent,"~ 1 + (1|Team)")))
    } else if(model.type == "All"){
      lmer(data = df, as.formula(paste(dependent,"~ Target * SessionOrder + (1|Team)")))
    } else if(model.type == "NoInteraction" && !is.robust){
      lmer(data = df, as.formula(paste(dependent,"~ Target + SessionOrder + (1|Team)")))
    } else if(model.type == "NoInteraction_NoTarget" && !is.robust){
      lmer(data = df, as.formula(paste(dependent,"~ SessionOrder + (1|Team)")))
    } else if(model.type == "NoInteraction_NoSession" && !is.robust){
      lmer(data = df, as.formula(paste(dependent,"~ Target + (1|Team)")))
    } else if(model.type == "null" && is.robust){
      rlmer(data = df, as.formula(paste(dependent,"~ 1 + (1|Team)")))
    } else if(model.type == "All" && is.robust){
      rlmer(data = df, as.formula(paste(dependent,"~ Target * SessionOrder + (1|Team)")))
    } else if(model.type == "NoInteraction" && is.robust){
      rlmer(data = df, as.formula(paste(dependent,"~ Target + SessionOrder + (1|Team)")))
    } else if(model.type == "NoInteraction_NoTarget" && is.robust){
      rlmer(data = df, as.formula(paste(dependent,"~ SessionOrder + (1|Team)")))
    } else if(model.type == "NoInteraction_NoSession" && is.robust){
      rlmer(data = df, as.formula(paste(dependent,"~ Target + (1|Team)")))
    } else{
      stop("Model.type not supported")
    }
  } else {
    # Run this code if individual level model
    if(model.type == "null" && !is.robust){
      lmer(data = df, as.formula(paste(dependent,"~ 1 + (1|Team) + (1| Player_ID)")))
    } else if(model.type == "All" && !is.robust){
      lmer(data = df, as.formula(paste(dependent,"~ Target * SessionOrder + (1|Team) + (1| Player_ID)")))
    } else if(model.type == "NoInteraction" && !is.robust){
      lmer(data = df, as.formula(paste(dependent,"~ Target + SessionOrder + (1|Team) + (1| Player_ID)")))
    } else if(model.type == "NoInteraction_NoTarget" && !is.robust){
      lmer(data = df, as.formula(paste(dependent,"~ SessionOrder + (1|Team) + (1| Player_ID)")))
    } else if(model.type == "NoInteraction_NoSession"){
      lmer(data = df, as.formula(paste(dependent,"~ Target + (1|Team) + (1| Player_ID)")))
    } else if(model.type == "null" && is.robust){
      rlmer(data = df, as.formula(paste(dependent,"~ 1 + (1|Team) + (1| Player_ID)")))
    } else if(model.type == "All" && is.robust){
      rlmer(data = df, as.formula(paste(dependent,"~ Target * SessionOrder + (1|Team) + (1| Player_ID)")))
    } else if(model.type == "NoInteraction" && is.robust){
      rlmer(data = df, as.formula(paste(dependent,"~ Target + SessionOrder + (1|Team) + (1| Player_ID)")))
    } else if(model.type == "NoInteraction_NoTarget" && is.robust){
      rlmer(data = df, as.formula(paste(dependent,"~ SessionOrder + (1|Team) + (1| Player_ID)")))
    } else if(model.type == "NoInteraction_NoSession" && is.robust){
      rlmer(data = df, as.formula(paste(dependent,"~ Target + (1|Team) + (1| Player_ID)")))
    } else{
      stop("Model.type not supported")
    }
  }
}

#Folder locations ----
figure_directory <- "C:\\Users\\jamia\\Box\\TMET2\\DATA TMET2\\Data_And_Calcuations\\Figures"
main_work_directory_name <- "C:\\Users\\jamia\\Box\\TMET2\\DATA TMET2\\Data_And_Calcuations\\Raw Data\\"

database_folder_name <- "Database"
file_name_output <- "team_player_aggragate_stats.csv"
folder_location_database <- paste(main_work_directory_name, database_folder_name, sep = "")
aggregate_folder_location <- paste(folder_location_database,"\\", file_name_output, sep = "") #This will combine the final file name and the desiered folder location

# Read aggregaate data ----
my_aggregate_data <- read.csv(file =  aggregate_folder_location)

clean_aggregate_data_stats <- remove_measures_with_given_value(data_set =  my_aggregate_data, col_name = "Condition", value = "A") # without none condition

# Re factor the columns
columns_to_refactor <- c("SessionOrder", 
                         "Team", 
                         "Player_ID", 
                         "Condition", 
                         "Dominate.Strategy", 
                         "Condition", 
                         "Target",
                         "Confident_team_comm_important_details_quickly")
clean_aggregate_data_stats <- re_factor_columns(clean_aggregate_data_stats, columns_to_refactor)

# What is the N for Teams ----
N_teams <- length(levels(factor(clean_aggregate_data_stats$Team)))

# What is the N for Inds ----
N_ind <- length(levels(factor(clean_aggregate_data_stats$Player_ID) ))

# Team data set ----
team_data <- clean_aggregate_data_stats %>%
  filter(Player == 1)

# Individual data set ----
ind_data <- clean_aggregate_data_stats

```

## Purpose

The purpose of this document is to record the data analysis for my Dissertation.

## Experimental Design

This experiment is a within-subject experimental design. The primary variable was the feedback condition (i.e., Target). There were four feedback conditions; None, Individual, Team, and Ind_Team Each team experienced each condition. The first condition for each group was the None condition. The remaining three conditions were counterbalanced. For example, the condition order for team 7 is the following: None, Ind, Team, Ind_Team. The condition order for group 8 is the following: None, Team, Individual, Ind_Team. 

## Data Description

I collected data from **`r N_ind`** participants that formed **`r N_teams`** teams. Below is a sample of the data for the main metrics

```{r main_metrics_table, echo=FALSE}
dt <- clean_aggregate_data_stats[1:5,c("TeamScore", 
                           "IndividualScore", 
                           "CI_team", 
                           "CI_ind", 
                           "II_team", 
                           "II_ind", 
                           "ERROR_team_unique", 
                           "ERROR_ind_unique", 
                           "ERROR_team_total",
                           "ERROR_ind_total")] 
dt %>%
  kable() %>%
  kable_styling()
```

## Research Question

This research attempts to answer the following question: *How will teams' performance change if given feedback that displays indicators based on individual performance, team performance, or both?*

## Exploratory Data Analysis

In this section, I seek to visually discover answers to the research question mentioned above.

### Q: Is there exciting variation among the *`r params$dependent_response_name_WithSpace`* metric that will help me understand the influence of the feedback condition?

#### Team

```{r }
#dependent_response_team <-  "II_team"
y_label_team <- "Count"
x_label_team <- params$dependent_response_name_WithSpace
title_response_team <- paste("Distribution of", params$dependent_response_name_WithSpace, "(Team)")
plot_name <- paste("Histogram_", params$dependent_response_name_NoSpace, "_Team.png", sep="")
setwd(figure_directory)

plot_data_team <- team_data %>%
  select(params$dependent_response_team, Target)

ggplot(data = plot_data_team) + 
  geom_histogram(aes_string(x = params$dependent_response_team), bins = 30) +
  labs(title = title_response_team, x = x_label_team, y = y_label_team) +
  ggsave(filename = plot_name)
```

The figure shows a skew in the data. The data skew to the left. It is showed that most teams collected 2 or less incorrect items.

```{r}
#dependent_response_team <- "II_team"
y_label_team <- "Count"
x_label_team <- "Target"
title_response_team <- paste("Distribution of", params$dependent_response_name_WithSpace, "(Team)")
plot_name <- paste("Histogram_", params$dependent_response_name_NoSpace, "_ByTarget_Team.png", sep="")
setwd(figure_directory)

plot_data_team <- team_data %>%
  select(params$dependent_response_team, Target)

ggplot(data = plot_data_team) + 
  geom_histogram(aes_string(x = params$dependent_response_team), bins = 30) +
  facet_grid(. ~ Target) +
  labs(title = title_response_team, x = x_label_team, y = y_label_team) +
  ggsave(filename = plot_name)

# Information about the N values in each condition
tableData <- team_data %>%
  group_by(Target) %>%
  summarise(N = length(.data[[params$dependent_response_team]]))

tableData %>%
  kable() %>%
  kable_styling()
```

Overal, when grouping the data by Target, each group has a distrabution similar to the overall distrabution. 

#### Individual

```{r}
# dependent_response_ind <- "II_ind"
y_label_ind <- "Count"
x_label_ind <- params$dependent_response_name_WithSpace
title_response_ind <- paste("Distribution of", params$dependent_response_name_WithSpace, "(Individual)")
plot_name <- paste("Histogram_", params$dependent_response_name_NoSpace, "_Ind.png", sep="")
setwd(figure_directory)

plot_data_ind <- ind_data %>%
  select(params$dependent_response_ind, Target)

ggplot(data = plot_data_ind) + 
  geom_histogram(aes_string(x = params$dependent_response_ind), bins = 30) +
  labs(title = title_response_ind, x = x_label_ind, y = y_label_ind) +
  ggsave(filename = plot_name)
```

The data shows a skew to the left. Specifically, the data shows that most participants collect 1 or less incorrect items. 

```{r}
# dependent_response_ind <- "II_ind"
y_label_ind <- "Count"
x_label_ind <- params$dependent_response_name_WithSpace
title_response_ind <- paste("Distribution of", params$dependent_response_name_WithSpace, "(Individual)")
plot_name <- paste("Histogram_", params$dependent_response_name_NoSpace, "_ByTarget_Ind.png", sep="")
setwd(figure_directory)

plot_data_ind <- ind_data %>%
  select(params$dependent_response_ind, Target)

ggplot(data = plot_data_ind) + 
  geom_histogram(aes_string(x = params$dependent_response_ind), bins = 30) +
  facet_grid(. ~ Target) +
  labs(title = title_response_ind, x = x_label_ind, y = y_label_ind) +
  ggsave(filename = plot_name)

# Information about the N values in each condition
tableData <- ind_data %>%
  group_by(Target) %>%
  summarise(N = length(.data[[params$dependent_response_ind]]))

tableData %>%
  kable() %>%
  kable_styling()
```

The figure shows that the distribution of the Target groups is similar to overall distrubution. 

#### Summary / Reflection

The The results show that the data is skweed to the left. At the team level, most groups 2 or less incorrect items and at the individual level most participants collected 1 or 0 incorrect items. There were not interesting findings when data was grouped by Target level. 

### Q: Is there exciting variation among the *`r params$dependent_response_name_WithSpace`* that explains how the feedback conditions influence the *`r params$dependent_response_name_WithSpace`* when session order is taken into consideration?

#### Team 

```{r}
#dependent_response_team <- "II_team"
y_label_team <- "Count"
x_label_team <- params$dependent_response_name_WithSpace
title_response_team <- paste("Distribution of", params$dependent_response_name_WithSpace, "(Team)")
plot_name <- paste("Histogram_", params$dependent_response_name_NoSpace, "_ByTarget_BySessionOrder_Team.png", sep="")
setwd(figure_directory)

plot_data_team <- team_data %>%
  select(params$dependent_response_team, Target, SessionOrder)

ggplot(data = plot_data_team) + 
  geom_histogram(aes_string(x = params$dependent_response_team), bins = 30) +
  labs(title = title_response_team, x = x_label_team, y = y_label_team) +
  facet_grid( SessionOrder ~ Target) + 
  ggsave(filename = plot_name)

# Information about the N values in each condition
tableData <- team_data %>%
  select(params$dependent_response_team, Target, SessionOrder) %>%
  group_by(Target, SessionOrder) %>%
  summarise(N = length(.data[[params$dependent_response_team]]))

tableData %>%
  kable() %>%
  kable_styling()
```

Over time, I would expect the data to skew to the left. 

In the Ind condition, it looks as though the groups did not improve over time. The distrabution seems to "faltten" as opposed to skewing to the left. 

The Ind_Team and Team condition both seem to improve over time. It does seem as though the groups in the Team condition, improve more than group in the Ind_Team and Ind condition. 

#### Individual 

```{r}
# dependent_response_ind <- "II_ind"
y_label_ind <- "Count"
x_label_ind <- params$dependent_response_name_WithSpace
title_response_ind <- paste("Distribution of", params$dependent_response_name_WithSpace, "(Individual)")
plot_name <- paste("Histogram_", params$dependent_response_name_NoSpace, "_ByTarget_BySessionOrder_Ind.png")
setwd(figure_directory)

plot_data_ind <- ind_data %>%
  select(params$dependent_response_ind, Target, SessionOrder)

ggplot(data = plot_data_ind) + 
  geom_histogram(aes_string(x = params$dependent_response_ind), bins = 30) +
  facet_grid(SessionOrder ~ Target) +
  labs(title = title_response_ind, x = x_label_ind, y = y_label_ind) +
  ggsave(filename = plot_name)

# Information about the N values in each condition
tableData <- ind_data %>%
  select(params$dependent_response_ind, Target, SessionOrder) %>%
  group_by(Target, SessionOrder) %>%
  summarise(N = length(.data[[params$dependent_response_ind]]))

tableData %>%
  kable() %>%
  kable_styling()
```

I see no interesting pattern in the figure. There does seem to be a general improvement in incorrect items collected (i.e., participants were not collecting wrong items) but most participants collect 1 or 0 incorrect items. 

#### Summary / Reflection

Overal, I see no intersting distrabutions at the individual or team level. 

### Q: Is there an *interaction* between the Target and Session Order for the __`r params$dependent_response_name_WithSpace`__?

I am interested in this question for modeling purposes. I want to know if I need to include the interaction between Target and Session Order. 

#### Team
```{r}
#dependent_response_team <- "II_team"
y_label_team <- params$dependent_response_name_WithSpace
x_label_team <- "Target"
title_response_team <- paste(params$dependent_response_name_WithSpace, "(Team) Vs. Target")
plot_name <- paste("InteractionPlot_", params$dependent_response_name_NoSpace, "_ByTarget_BySessionOrder_Team.png", sep="")
setwd(figure_directory)

plot_data_team <- team_data %>%
  select(Target, SessionOrder, params$dependent_response_team) %>%
  group_by(SessionOrder, Target) %>%
  summarise(dependentAverage = mean(.data[[params$dependent_response_team]]), 
            Stdv =sd(.data[[params$dependent_response_team]]), n = length(.data[[params$dependent_response_team]]), 
            StEr = sd(.data[[params$dependent_response_team]]) / sqrt(length(.data[[params$dependent_response_team]])))

ggplot(data = plot_data_team, aes(x = Target, y = dependentAverage, color = SessionOrder, shape = SessionOrder)) +
  geom_point(size = 3) +
  geom_line(aes(group=SessionOrder, color = SessionOrder)) + 
  geom_errorbar(aes(ymin = dependentAverage - StEr, ymax = dependentAverage + StEr), width = 0.2) +
  labs(y = y_label_team, x = x_label_team, title = title_response_team, color = "Session", shape = "Session") +
  ggsave(filename = plot_name)

plot_data_team %>%
  kable() %>%
  kable_styling()
```

The figure indicates there might be a small interaction between the two variables. Interstingly, on average, teams in the Ind_Team condition collected more incorrect items in session 3 that in session 2 or 4. Also, teams in the Ind condition did not seem to not imporve or get any worse. 

```{r}
#dependent_response_team <- "II_team"
y_label_team <- params$dependent_response_name_WithSpace
x_label_team <- "Target"
title_response_team <- paste(params$dependent_response_name_WithSpace, "(Team) Vs. Session Order")
plot_name <- paste("InteractionPlot_", params$dependent_response_name_NoSpace, "_BySessionOrder_ByTarget_Team.png")
setwd(figure_directory)

plot_data_team <- team_data %>%
  select(Target, SessionOrder, params$dependent_response_team) %>%
  group_by(SessionOrder, Target) %>%
  summarise(DependentAverage = mean(.data[[params$dependent_response_team]]), 
            Stdv =sd(.data[[params$dependent_response_team]]), n = length(.data[[params$dependent_response_team]]), 
            StEr = sd(.data[[params$dependent_response_team]]) / sqrt(length(.data[[params$dependent_response_team]])))

ggplot(data = plot_data_team, aes(x = SessionOrder , y = DependentAverage, color = Target, shape = Target)) +
  geom_point(size = 3) +
  geom_line(aes(group=Target, color = Target)) + 
  geom_errorbar(aes(ymin = DependentAverage - StEr, ymax = DependentAverage + StEr), width = 0.2) +
  labs(y = y_label_team, x = x_label_team, title = title_response_team, color = "Session", shape = "Session") +
  ggsave(filename = plot_name)
```

Overall, there seems to be an interaction between the two variables. I am not sure how big the interaction is since the differences in the averages are samll. 


#### Individual

```{r}
# dependent_response_ind <- "II_ind"
y_label_ind <- params$dependent_response_name_WithSpace
x_label_ind <- "Target"
title_response_ind <- paste(params$dependent_response_name_WithSpace, "(Individual) Vs. Target")
plot_name <- paste("InteractionPlot_", params$dependent_response_name_NoSpace, "_ByTarget_BySessionOrder_Ind.png", sep="")
setwd(figure_directory)

plot_data_ind <- ind_data %>%
  select(Target, SessionOrder, params$dependent_response_ind) %>%
  group_by(SessionOrder, Target) %>%
  summarise(Average = mean(.data[[params$dependent_response_ind]]), 
            Stdv =sd(.data[[params$dependent_response_ind]]), 
            n = length(.data[[params$dependent_response_ind]]), 
            StEr = sd(.data[[params$dependent_response_ind]]) / sqrt(length(.data[[params$dependent_response_ind]])))

ggplot(data = plot_data_ind, aes(x = Target, y = Average, color = SessionOrder, shape=SessionOrder)) +
  geom_point(size = 3) +
  geom_line(aes(group=SessionOrder, color = SessionOrder)) + 
  geom_errorbar(aes(ymin = Average - StEr, ymax = Average + StEr), width = 0.2) +
  labs(y = y_label_ind, x = x_label_ind, title = title_response_ind, fill = "Players") + 
  ggsave(filename = plot_name)

plot_data_ind %>%
  kable() %>%
  kable_styling()
```

The figure shows that there may be a small interaction between the two variables. 

It is interesting to note that in the Ind condition the particiapnts did not imporove in there ability to avoid collecting incorrect items. It also, shows that the did not get any worse.

It is also intersting to note that it seems as though participants in the team conditon improves the most from session 2 to 4. 

```{r}
# dependent_response_ind <- "II_ind"
y_label_ind <- params$dependent_response_name_WithSpace
x_label_ind <- "Target"
title_response_ind <- paste(params$dependent_response_name_WithSpace, "(Individual) Vs. Target")
plot_name <- paste("InteractionPlot_", params$dependent_response_name_NoSpace, "_BySessionOrder_ByTarget_Ind.png", sep="")
setwd(figure_directory)

plot_data_ind <- ind_data %>%
  select(Target, SessionOrder, params$dependent_response_ind) %>%
  group_by(SessionOrder, Target) %>%
  summarise(Average = mean(.data[[params$dependent_response_ind]]), 
            Stdv =sd(.data[[params$dependent_response_ind]]), 
            n = length(.data[[params$dependent_response_ind]]), 
            StEr = sd(.data[[params$dependent_response_ind]]) / sqrt(length(.data[[params$dependent_response_ind]])))

ggplot(data = plot_data_ind, aes(x = SessionOrder, y = Average, color = Target, shape=Target)) +
  geom_point(size = 3) +
  geom_line(aes(group=Target, color = Target)) + 
  geom_errorbar(aes(ymin = Average - StEr, ymax = Average + StEr), width = 0.2) +
  labs(y = y_label_ind, x = x_label_ind, title = title_response_ind, fill = "Players") +
  ggsave(filename = plot_name)
```

Overall, there seems to be a small interaction between the two variables.

#### Summary / Reflection

Overall, there does seem to be some interaction between the two variables (i.e., Target and Session Order) but they seem to be small. Statisticall analysis is needed to determine if the interaction should be included when modeling the data. 

### Q: Is there an interaction between the Target and Session Order for the __`r params$dependent_response_name_WithSpace`__ that is statistically significant?

I am interested in determining if a linear mixed effect model should include the interaction effect between the Target and Session Order variable.

There are a few steps I will take. First, I will fit the multiple models using the data provided. Second, I will compare those models to the null model. Third, I will pick the models that are worth exploring further (e.g., models that are significantly different from the null model). Fourth, I will evaluate the effect size ($R^2$) of the fixed effect and random effect variables using a method by [@Nakagawa2013, @Johnson2014]. Lastly, I will analyze the assumptions for the residuals. 

A note on the effect size ($R^2$). This method generates two types of ($R^2$) values called marginal ($R_{m}^2$) and conditional ($R_{c}^2$) effect size. The $R_{m}^2$ calculates how much of the variance is described by the fixed effect variables (feedback condition and session order) while the $R_{c}^2$ calculates how much of the variance is described by both the fixed and random effect variables.

#### Full Models Used for Team and Individual

The next two sections below describe the full model for team and individual level analysis. Five models were fitted and then compared. One model was the null model, one model was the full model, and the last three are a subset of the full model.

##### Team Full Model

$$ y_{ijt} = \mu + \alpha_{i} + \beta_{j} + \alpha_{i} \beta_{j} + \gamma_{t} +   \epsilon_{ijt}$$ 

Where $y_{ijt}$ is the response variable (e.g., team score), $\mu$ is the baseline (or intercept), $\alpha_{i}$ is the fixed effect for the $i^(th)$ feedback target category, $\beta_{j}$ is the fixed effect for the $j^(th)$ session order, $\gamma_{t}$ is the random effect for the $t^(th)$ team, $ \alpha_{i} \beta_{j}$ is the fixed effect of the interaction between Target and Session Order, and $\epsilon_{ijt}$ is the residual for the model. 

##### Individual Team Full Model

$$ y_{ijtp} = \mu + \alpha_{i} + \beta_{j} + \alpha_{i} \beta_{j} + \gamma_{t} + \theta_{p} + \epsilon_{ijtp}$$ 

Where $y_{ijtp}$ is the response variable (e.g., individual score), $\mu$ is the baseline (or intercept), $\alpha_{i}$ is the fixed effect for the $i^(th)$ feedback target category, $\beta_{j}$ is the fixed effect for the $j^(th)$ session order, $\gamma_{t}$ is the random effect for the $t^(th)$ team, $\theta_{p}$ is the random effect for the $p^(th)$ individual, $ \alpha_{i} \beta_{j}$ is the fixed effect of the interaction between Target and Session Order, and $\epsilon_{ijtp}$ is the residual for the model.


##### Team

```{r message=FALSE}
# Response variable
#response_variable <- "II_team" 

# Data to fit
data_modified_team <- team_data %>%
  select(TeamScore,
         params$dependent_response_team,
         Target, 
         SessionOrder, 
         Team)

# Generate models with variable response
data_focus_team <- data_modified_team
model.null <- model_data_Target_Session(df = data_focus_team, dependent =  params$dependent_response_team, model.type =  "null", is.team = TRUE, is.robust =FALSE)
model.All <- model_data_Target_Session(df = data_focus_team, dependent =  params$dependent_response_team, model.type =  "All", is.team = TRUE, is.robust = FALSE)
model.NoInteraction <- model_data_Target_Session(df = data_focus_team, dependent =  params$dependent_response_team, model.type =  "NoInteraction", is.team = TRUE, is.robust = FALSE)
model.NoInteraction.NoTarget <- model_data_Target_Session(df = data_focus_team, dependent =  params$dependent_response_team, model.type =  "NoInteraction_NoTarget", is.team = TRUE, is.robust = FALSE)
model.NoInteraction.NoSession <- model_data_Target_Session(df = data_focus_team, dependent =  params$dependent_response_team, model.type =  "NoInteraction_NoSession", is.team = TRUE, is.robust = FALSE)

# There is an option to compare all the models with the anova(). However, the function does not compare all models to model.null
anova(model.null,
      model.All) %>%
  kable(caption = "ANOVA: Null and All") %>%
  kable_styling()

anova(model.null,
      model.NoInteraction) %>%
  kable(caption = "ANOVA: Null and No.Interaction") %>%
  kable_styling()

anova(model.null,
      model.NoInteraction.NoTarget) %>%
  kable(caption = "ANOVA: Null and No.Interaction.No.Target") %>%
  kable_styling()

anova(model.null,
      model.NoInteraction.NoSession) %>%
  kable(caption = "ANOVA: Null and No.Interaction.No.Session") %>%
  kable_styling()

```

__Reflection:__ None of the models above seem to be significantly different from model.null. This suggests that none of the models seem to describe the data better than no model at all. If this is true, then this means that no further analysis is needed.

However, I will conduct further analysis of at least one model. I will look at the effect size of each model and determine the model that has the highest effect size. 

```{r}
# Response variable
#response_variable <- "II_team"

# Data to fit
data_modified_team <- team_data %>%
  select(TeamScore,
         params$dependent_response_team,
         Target, 
         SessionOrder, 
         Team)

# Generate models with variable response
data_focus_team <- data_modified_team

model.All <- model_data_Target_Session(df = data_focus_team, dependent =  params$dependent_response_team, model.type =  "All", is.team = TRUE, is.robust = FALSE)
model.NoInteraction <- model_data_Target_Session(df = data_focus_team, dependent =  params$dependent_response_team, model.type =  "NoInteraction", is.team = TRUE, is.robust = FALSE)
model.NoInteraction.NoTarget <- model_data_Target_Session(df = data_focus_team, dependent =  params$dependent_response_team, model.type =  "NoInteraction_NoTarget", is.team = TRUE, is.robust = FALSE)
model.NoInteraction.NoSession <- model_data_Target_Session(df = data_focus_team, dependent =  params$dependent_response_team, model.type =  "NoInteraction_NoSession", is.team = TRUE, is.robust = FALSE)

# Effect size (R^2)
r.squaredGLMM(model.All) %>%
  kable(caption = "Table: Effect size for *All*") %>%
   kable_styling(full_width = F)

r.squaredGLMM(model.NoInteraction) %>%
  kable(caption = "Table: Effect size for *No Interaction*") %>%
   kable_styling(full_width = F)

r.squaredGLMM(model.NoInteraction.NoTarget) %>%
  kable(caption = "Table: Effect size for *No Interaction and No Target*") %>%
   kable_styling(full_width = F)

r.squaredGLMM(model.NoInteraction.NoSession) %>%
  kable(caption = "Table: Effect size for *No Interaction and No Session*") %>%
   kable_styling(full_width = F)
```

__Reflection:__ The results do not show any major difference between the effect sizes. No model has a conditional effect size that is greater than 0.5. In other words, no model explains more than 50% of the variance.  

Overall, no model fits the data well. This tells me that the variance (i.e., Target and Session Order) do not explain the Incorrect items collected. However, I believe that this is because of the average incorrect items collected at less than 1 items. In other words, the teams infrequently collected incorrect team items. As a result, this tells me that it is difficult to use this dependent variable to differentiate between good and bad teams. For further analysis, I will examine __model.NoInteraction__ since this is the model I am most interested in learning more about.

##### Individual

```{r}
# Response Variable

#response_variable <- "II_ind"

# Data to model
data_modified_ind <- ind_data %>%
  select(params$dependent_response_ind,
         Target, 
         SessionOrder, 
         Team, 
         Player_ID)

data_focus_ind <- data_modified_ind
model.null <- model_data_Target_Session(df = data_focus_ind, dependent =  params$dependent_response_ind, model.type =  "null", is.team = FALSE, is.robust = FALSE)
model.All <- model_data_Target_Session(df = data_focus_ind, dependent =  params$dependent_response_ind, model.type =  "All", is.team = FALSE, is.robust = FALSE)
model.NoInteraction <- model_data_Target_Session(df = data_focus_ind, dependent =  params$dependent_response_ind, model.type =  "NoInteraction", is.team = FALSE, is.robust = FALSE)
model.NoInteraction.NoTarget <- model_data_Target_Session(df = data_focus_ind, dependent =  params$dependent_response_ind, model.type =  "NoInteraction_NoTarget", is.team = FALSE, is.robust = FALSE)
model.NoInteraction.NoSession <- model_data_Target_Session(df = data_focus_ind, dependent =  params$dependent_response_ind, model.type =  "NoInteraction_NoSession", is.team = FALSE, is.robust = FALSE)

# There is an option to compare all the models with the anova(). However, the function does not compare all models to model.null
anova(model.null,
      model.All) %>%
  kable(caption = "ANOVA: model.null and model.All") %>%
  kable_styling()

anova(model.null,
      model.NoInteraction) %>%
  kable(caption = "ANOVA: model.null and model.NoInteraction") %>%
  kable_styling()

anova(model.null,
      model.NoInteraction.NoTarget) %>%
  kable(caption = "ANOVA: model.null and model.NoInteraction.NoTarget") %>%
  kable_styling()

anova(model.null,
      model.NoInteraction.NoSession) %>%
  kable(caption = "ANOVA: model.null and model.NoInteraction.NoSession") %>%
  kable_styling()
```

__Reflection:__ None of the models above seem to be significantly different from model.null. This suggests that none of the models seem to describe the data better than no model at all. If this is true, then this means that no further analysis is needed.

However, I will conduct further analysis of at least one model. I will look at the effect size of each model and determine the model that has the highest effect size. 

```{r}
# Response Variable

#response_variable <- "II_ind"

# Data to model
data_modified_ind <- ind_data %>%
  select(params$dependent_response_ind,
         Target, 
         SessionOrder, 
         Team, 
         Player_ID)

data_focus_ind <- data_modified_ind
model.All <- model_data_Target_Session(df = data_focus_ind, dependent =  params$dependent_response_ind, model.type =  "All", is.team = FALSE, is.robust = FALSE)
model.NoInteraction <- model_data_Target_Session(df = data_focus_ind, dependent =  params$dependent_response_ind, model.type =  "NoInteraction", is.team = FALSE, is.robust = FALSE)
model.NoInteraction.NoTarget <- model_data_Target_Session(df = data_focus_ind, dependent =  params$dependent_response_ind, model.type =  "NoInteraction_NoTarget", is.team = FALSE, is.robust = FALSE)
model.NoInteraction.NoSession <- model_data_Target_Session(df = data_focus_ind, dependent =  params$dependent_response_ind, model.type =  "NoInteraction_NoSession", is.team = FALSE, is.robust = FALSE)

# Effect size (R^2)
r.squaredGLMM(model.All) %>%
  kable(caption = "Table: Effect size for *All*") %>%
   kable_styling(full_width = F)

r.squaredGLMM(model.NoInteraction) %>%
  kable(caption = "Table: Effect size for *No Interaction*") %>%
   kable_styling(full_width = F)

r.squaredGLMM(model.NoInteraction.NoTarget) %>%
  kable(caption = "Table: Effect size for *No Interaction and No Target*") %>%
   kable_styling(full_width = F)

r.squaredGLMM(model.NoInteraction.NoSession) %>%
  kable(caption = "Table: Effect size for *No Interaction and No Session*") %>%
   kable_styling(full_width = F)
```

__Reflection:__ The results do not show any major difference between the effect sizes. No model has a conditional effect size that is greater than 0.25. In other words, no model explains more than 25% of the variance.

##### Summary / Reflection

Overall, no model fits the data well. This tells me that the variance (i.e., Target and Session Order) do not explain the Incorrect items collected. However, I believe that this is because of the average incorrect items collected at less than 1 items. In other words, the participants infrequently collected incorrect individual items. As a result, this tells me that it is difficult to use this dependent variable to differentiate between good and bad participants. For further analysis, I will examine __model.NoInteraction__ since this is the model I am most interested in learning more about.

### Q: Are any of the effects in the models statistically different from zero?

The purpose of this question is to see what we can learn from these models. Before I examine the model by generating diagnostic plots for the models. The assumptions are as follows [@Galwey2014]:

1. The residuals should have an approximately normal distribution (i.e., a bell curve) when plotted on a histogram.
2. A fitted-value plot should show an almost constant width when viewed from left to right.
3. The points on a normal plot should lie on an almost straight line from the bottom left to the top right.

The models may violate some of the assumptions. According to @Field2017, the best way to examine the influence of assumption violations is to compare a robust model to a standard model. When models violate assumptions, I will compare a robust model to a classic model. If there is a noticeable difference between the two models (i.e., if the estimated coefficient are noticeably different) then I will use a step on the power ladder to transform (@Tukey1977), or re-express, the data to address the assumption violation.

#### Team

We learned that no model was best at describing the data. However, I will exmaine the __model.NoInteraction__ because it is the model I am interested in examining (see previous analysis).

```{r}
# Response variable
#response_variable <- "II_team"
#plot_dependent_variable_name <- "II" 

# Data to fit
data_modified_team <- team_data %>%
  select(TeamScore,
         params$dependent_response_team,
         Target, 
         SessionOrder, 
         Team)

# Plot location
setwd(figure_directory)

# Generate models with variable response
data_focus_team <- data_modified_team
model.NoInteraction <- model_data_Target_Session(df = data_focus_team, dependent =  params$dependent_response_team, model.type =  "NoInteraction", is.team = TRUE, is.robust = FALSE)

# Histogram of Residuals - model.NoInteraction
ggplot(model.NoInteraction, aes(x = .resid)) +
  geom_histogram(bins = 30) + 
  labs(title = paste("Histogram of Residuals for model.NoInteraction"), x = "", y = "") +
  theme(plot.title = element_text(hjust = 0.5)) +
  ggsave(filename = paste("Histogram_Residuals_", params$dependent_response_name_NoSpace, "_NoInteraction_Team.png", sep = ""))

# Fitted values - model.NoInteraction
ggplot(model.NoInteraction, aes(x = .fitted, y = .resid)) +
  geom_point() + 
  geom_hline(yintercept = 0)+
  labs(title = paste("Fitted-Value Plot for model.NoInteraction"), x = "Fitted Values", y = "Residuals") +
  theme(plot.title = element_text(hjust = 0.5)) +
  ggsave(filename = paste("FitteValue_Residuals_", params$dependent_response_name_NoSpace, "_NoInteraction_Team.png", sep = ""))

# QQ plots - model.NoInteraction
ggplot(model.NoInteraction, aes(sample = .resid)) +
  stat_qq() +
  stat_qq_line()+
  labs(title = "Normal Q-Q Plot for NoInteraction", x = "Theoretical", y = "Sample") +
   theme(plot.title = element_text(hjust = 0.5)) +
  ggsave(filename = paste("QQ_Residuals_", params$dependent_response_name_NoSpace, "_NoInteraction_Team.png", sep = ""))
```

__model.NoInteraction__: Visually, it looks like assumptions 2 and 3 are violated in the fitted-value plot and the QQ plot, respectively. It also looks as though there may be a slight skew in the histogram distribution as well. I will need to compare this model to a robust model to examine the influence of the apparent violation. If there is a noticeable difference, I will need to transform the data.

##### Q: Does the violation influence the linear model estimation?

I will use the robust estimation for linear mixed models found in the robustlmm package by @Koller2016. I will then compare the robust model to the non-robust model. If the estimated values are noticeably different, then the data will need to be transformed. 

###### Model.NoInteraction

```{r}
# Response Variable
#response_variable <- "II_team"

# Data to fit
data_modified_team <- team_data %>%
  select(TeamScore,
         params$dependent_response_team,
         Target, 
         SessionOrder, 
         Team)

data_focus_team <- data_modified_team

# Generate robust and non-robust models - NoInteraction
model.NoInteraction <- model_data_Target_Session(df = data_focus_team, dependent =  params$dependent_response_team, model.type =  "NoInteraction", is.team = TRUE, is.robust = FALSE)
rmodel.NoInteraction <- model_data_Target_Session(df = data_focus_team, dependent =  params$dependent_response_team, model.type =  "NoInteraction", is.team = TRUE, is.robust = TRUE)

comparision_results <- compare(model.NoInteraction, rmodel.NoInteraction, show.rho.functions = FALSE)

comparision_results %>%
  kable(caption = "model.NoInteraction") %>%
  kable_styling()
```

I am concerned with the differeny values generated in the differen models. I will transform the data.

##### Q: Does data transformation satisfy the assumptions of the residuals?

I will use the square root transformation method from Tukey's ladder [@Tukey1977].

###### Model.NoInteraction

```{r}
# Response Variable
#response_variable <- "II_team"
# plot_dependent_variable_name <- "II"

# Data to fit
data_modified_team <- team_data %>%
  select(TeamScore,
         params$dependent_response_team,
         Target, 
         SessionOrder, 
         Team) %>%
  mutate(sqrt.value = sqrt(.data[[params$dependent_response_team]]))

#response_variable <- "sqrt.value"
data_focus_team <- data_modified_team

#Plot location
setwd(figure_directory)

# Generate non-robust models - NoInteraction
model.NoInteraction <- model_data_Target_Session(df = data_focus_team, dependent =  "sqrt.value", model.type =  "NoInteraction", is.team = TRUE, is.robust = FALSE)

# Histogram of Residuals - model.NoInteraction
ggplot(model.NoInteraction, aes(x = .resid)) +
  geom_histogram(bins = 30) + 
  labs(title = paste("Histogram of Residuals for model.NoInteraction"), x = "", y = "") +
  theme(plot.title = element_text(hjust = 0.5)) +
  ggsave(paste("Histogram_Residuals_", params$dependent_response_name_NoSpace, "_sqrt_NoInteraction_Team.png", sep = ""))

# Fitted values - model.NoInteraction
ggplot(model.NoInteraction, aes(x = .fitted, y = .resid)) +
  geom_point() + 
  geom_hline(yintercept = 0)+
  labs(title = paste("Fitted-Value Plot for model.NoInteraction"), x = "Fitted Values", y = "Residuals") +
  theme(plot.title = element_text(hjust = 0.5)) +
  ggsave(paste("FitteValue_Residuals_", params$dependent_response_name_NoSpace, "_sqrt_NoInteraction_Team.png", sep = ""))

# QQ plots - model.NoInteraction
ggplot(model.NoInteraction, aes(sample = .resid)) +
  stat_qq() +
  stat_qq_line()+
  labs(title = "Normal Q-Q Plot for model.NoInteraction", x = "Theoretical", y = "Sample") +
   theme(plot.title = element_text(hjust = 0.5)) + 
  ggsave(paste("QQ_Residuals_", params$dependent_response_name_NoSpace, "_sqrt_NoInteraction_Team.png", sep = ""))
```

The diagonstic not show a violation of all assumptions. I will need to compare the robust models to examine the influence of the violations. 

```{r}
# Response Variable
#response_variable <- "II_team"

# Data to fit
data_modified_team <- team_data %>%
  select(TeamScore,
         params$dependent_response_team,
         Target, 
         SessionOrder, 
         Team) %>%
  mutate(sqrt.value = sqrt(.data[[params$dependent_response_team]]))

#response_variable <- "sqrt.value"
data_focus_team <- data_modified_team

# Generate robust and non-robust models - NoInteraction
model.NoInteraction <- model_data_Target_Session(df = data_focus_team, dependent =  "sqrt.value", model.type =  "NoInteraction", is.team = TRUE, is.robust = FALSE)
rmodel.NoInteraction <- model_data_Target_Session(df = data_focus_team, dependent =  "sqrt.value", model.type =  "NoInteraction", is.team = TRUE, is.robust = TRUE)

comparision_results <- compare(model.NoInteraction, rmodel.NoInteraction, show.rho.functions = FALSE)

comparision_results %>%
  kable(caption = "model.NoInteraction") %>%
  kable_styling()
```

I see no concerning difference between the two models. The similarity between the two models indicates to me that the apparent violations of the transformed data does not have a major impact on the model. 

##### Q: Are there any effects that are significant?

I want to determine if Target has a significant effect. I will examine the model itself, and then I will calculate the estimated marginal means to compare all three levels.

###### Model.NoInteraction

```{r}
# Response Variable
#response_variable <- "II_team"

# Data to fit
data_modified_team <- team_data %>%
  select(TeamScore,
         params$dependent_response_team,
         Target, 
         SessionOrder, 
         Team) %>%
  mutate(sqrt.value = sqrt(.data[[params$dependent_response_team]]))

#response_variable <- "sqrt.value"
data_focus_team <- data_modified_team

# Generate robust and non-robust models - NoInteraction
model.NoInteraction <- model_data_Target_Session(df = data_focus_team, dependent =  "sqrt.value", model.type =  "NoInteraction", is.team = TRUE, is.robust = FALSE)

summary(model.NoInteraction)
```

The results show that none of the levles for the Target or Session Order variables are significantly differeny from the Ind level or the session 2. 

```{r}
# Response Variable
#response_variable <- "II_team"

# Data to fit
data_modified_team <- team_data %>%
  select(TeamScore,
         params$dependent_response_team,
         Target, 
         SessionOrder, 
         Team) %>%
  mutate(sqrt.value = sqrt(.data[[params$dependent_response_team]]))

#response_variable <- "sqrt.value"
data_focus_team <- data_modified_team

# Generate robust and non-robust models - NoInteraction
model.NoInteraction <- model_data_Target_Session(df = data_focus_team, dependent =  "sqrt.value", model.type =  "NoInteraction", is.team = TRUE, is.robust = FALSE)

emmeans(model.NoInteraction, list(pairwise ~ Target), adjust = "tukey")
```

The results show no significant difference among the Target levels. 

```{r}
# Response Variable
#response_variable <- "II_team"

# Data to fit
data_modified_team <- team_data %>%
  select(TeamScore,
         params$dependent_response_team,
         Target, 
         SessionOrder, 
         Team) %>%
  mutate(sqrt.value = sqrt(.data[[params$dependent_response_team]]))

#response_variable <- "sqrt.value"
data_focus_team <- data_modified_team

# Generate robust and non-robust models - NoInteraction
model.NoInteraction <- model_data_Target_Session(df = data_focus_team, dependent =  "sqrt.value", model.type =  "NoInteraction", is.team = TRUE, is.robust = FALSE)

emmeans(model.NoInteraction, list(pairwise ~ SessionOrder), adjust = "tukey")
```

The results show no significant difference among the Session levels. 


##### Summary / Reflection

Overall, the model showed no unexpected or exciting significance. There was a lack of significance when examining the session order variable. 


#### Individual

We learned that no model was best at describing the data. However, I will exmaine the __model.NoInteraction__ because it is the model I am interested in examining (see previous analysis).

```{r}
# Response variable
#response_variable <- "II_ind"
# plot_dependent_variable_name <- "II"

# Data to model
data_modified_ind <- ind_data %>%
  select(params$dependent_response_ind,
         Target, 
         SessionOrder, 
         Team, 
         Player_ID)

# Plot location
setwd(figure_directory)

# Generate models with variable response

data_focus_ind <- data_modified_ind
model.NoInteraction <- model_data_Target_Session(df = data_focus_ind, dependent =  params$dependent_response_ind, model.type =  "NoInteraction", is.team = FALSE, is.robust = FALSE)

# Histogram of Residuals - model.NoInteraction
ggplot(model.NoInteraction, aes(x = .resid)) +
  geom_histogram(bins = 30) + 
  labs(title = paste("Histogram of Residuals for model.NoInteraction"), x = "", y = "") +
  theme(plot.title = element_text(hjust = 0.5)) +
  ggsave(paste("Histogram_Residuals_", params$dependent_response_name_NoSpace, "_NoInteraction_Ind.png", sep =""))

# Fitted values - model.NoInteraction
ggplot(model.NoInteraction, aes(x = .fitted, y = .resid)) +
  geom_point() + 
  geom_hline(yintercept = 0)+
  labs(title = paste("Fitted-Value Plot for model.NoInteraction"), x = "Fitted Values", y = "Residuals") +
  theme(plot.title = element_text(hjust = 0.5)) +
  ggsave(paste("FittedValue_Residuals_", params$dependent_response_name_NoSpace, "_NoInteraction_Ind.png", sep =""))


# QQ plots - model.NoInteraction
ggplot(model.NoInteraction, aes(sample = .resid)) +
  stat_qq() +
  stat_qq_line()+
  labs(title = "Normal Q-Q Plot for NoInteraction", x = "Theoretical", y = "Sample") +
   theme(plot.title = element_text(hjust = 0.5)) +
  ggsave(paste("QQ_Residuals_", params$dependent_response_name_NoSpace, "_NoInteraction_Ind.png", sep =""))

```

The plots show a clear violation of assumption 2 and 3. There is a slight skew in the historgram, which also indicates a violation of assumption 1. 

##### Q: Does the violation influence the linear model estimation?

I will use the robust estimation for linear mixed models found in the robustlmm package by @Koller2016. I will then compare the robust model to the non-robust model. If the estimated values are noticeably different, then the data will need to be transformed. 

###### Model.NoInteraction

```{r}
#response_variable <- "II_ind"

# Data to model
data_modified_ind <- ind_data %>%
  select(params$dependent_response_ind,
         Target, 
         SessionOrder, 
         Team, 
         Player_ID)

# Generate models with variable response
data_focus_ind <- data_modified_ind
model.NoInteraction <- model_data_Target_Session(df = data_focus_ind, dependent =  params$dependent_response_ind, model.type =  "NoInteraction", is.team = FALSE, is.robust = FALSE)
rmodel.NoInteraction <- model_data_Target_Session(df = data_focus_ind, dependent =  params$dependent_response_ind, model.type =  "NoInteraction", is.team = FALSE, is.robust = TRUE)

comparision_results <- compare(model.NoInteraction, rmodel.NoInteraction, show.rho.functions = FALSE)

comparision_results %>%
  kable(caption = "model.NoInteraction") %>%
  kable_styling()
```

__model.NoInteraction:__ I see concerning difference between the two models. I will need to transform the model.

##### Q: Does data transformation satisfy the assumptions of the residuals?

I will use the square root transformation method from Tukey's ladder [@Tukey1977]. 

###### Model.NoInteraction

```{r}
# Response variable
#response_variable <- "II_ind"
# plot_dependent_variable_name <- "II"

# Data to model
data_modified_ind <- ind_data %>%
  select(params$dependent_response_ind,
         Target, 
         SessionOrder, 
         Team, 
         Player_ID) %>%
  mutate(sqrt.value = sqrt(ifelse(.data[[params$dependent_response_ind]] < 0, 0, .data[[params$dependent_response_ind]]))) # Some of the time remaining vaules are negative when the should be zero. I want to make sure those values are zero

# Plot location
setwd(figure_directory)

#response_variable <- "sqrt.value"
data_focus_ind <- data_modified_ind

# Generate models with variable response
model.NoInteraction <- model_data_Target_Session(df = data_focus_ind, dependent =  "sqrt.value", model.type =  "NoInteraction", is.team = FALSE, is.robust = FALSE)

# Histogram of Residuals - model.NoInteraction
ggplot(model.NoInteraction, aes(x = .resid)) +
  geom_histogram(bins = 30) + 
  labs(title = paste("Histogram of Residuals for model.NoInteraction"), x = "", y = "") +
  theme(plot.title = element_text(hjust = 0.5)) + 
  ggsave(paste("Histogram_Residuals_", params$dependent_response_name_NoSpace, "_sqrt_NoInteraction_Ind.png", sep =""))


# Fitted values - model.NoInteraction
ggplot(model.NoInteraction, aes(x = .fitted, y = .resid)) +
  geom_point() + 
  geom_hline(yintercept = 0)+
  labs(title = paste("Fitted-Value Plot for model.NoInteraction"), x = "Fitted Values", y = "Residuals") +
  theme(plot.title = element_text(hjust = 0.5)) +
  ggsave(paste("FittedValue_Residuals_", params$dependent_response_name_NoSpace, "_sqrt_NoInteraction_Ind.png", sep =""))


# QQ plots - model.NoInteraction
ggplot(model.NoInteraction, aes(sample = .resid)) +
  stat_qq() +
  stat_qq_line()+
  labs(title = "Normal Q-Q Plot for NoInteraction", x = "Theoretical", y = "Sample") +
  theme(plot.title = element_text(hjust = 0.5)) +
  ggsave(paste("QQ_Residuals_", params$dependent_response_name_NoSpace, "_sqrt_NoInteraction_Ind.png", sep =""))

```

There still appears to be a violation of all three plots. So, I need to compare the robust and non-robust models to make sure I do not need to worry about this violation.

```{r}
#Response variable 
# response_variable <- "II_ind"

# Data to model
data_modified_ind <- ind_data %>%
  select(params$dependent_response_ind,
         Target, 
         SessionOrder, 
         Team, 
         Player_ID) %>%
  mutate(sqrt.value = sqrt(ifelse(.data[[params$dependent_response_ind]] < 0, 0, .data[[params$dependent_response_ind]]))) # Some fo the time remaining vaules are negative when the should be zero. I want to make sure those values are zero

# response_variable <- "sqrt.value"
data_focus_ind <- data_modified_ind

# Generate models with variable response
model.NoInteraction <- model_data_Target_Session(df = data_focus_ind, dependent =  "sqrt.value", model.type =  "NoInteraction", is.team = FALSE, is.robust = FALSE)
rmodel.NoInteraction <- model_data_Target_Session(df = data_focus_ind, dependent =  "sqrt.value", model.type =  "NoInteraction", is.team = FALSE, is.robust = TRUE)

compare(model.NoInteraction, rmodel.NoInteraction, show.rho.functions = FALSE) %>%
  kable() %>%
  kable_styling()
```

I see no concernable difference between the two models 


##### Q: Are there any effects that are significant?

###### Model.NoInteraction

```{r}
#Response variable 
# response_variable <- "II_ind"

# Data to model
data_modified_ind <- ind_data %>%
  select(params$dependent_response_ind,
         Target, 
         SessionOrder, 
         Team, 
         Player_ID) %>%
  mutate(sqrt.value = sqrt(ifelse(.data[[params$dependent_response_ind]] < 0, 0, .data[[params$dependent_response_ind]]))) # Some fo the time remaining vaules are negative when the should be zero. I want to make sure those values are zero

# response_variable <- "sqrt.value"
data_focus_ind <- data_modified_ind

# Generate models with variable response
model.NoInteraction <- model_data_Target_Session(df = data_focus_ind, dependent =  "sqrt.value", model.type =  "NoInteraction", is.team = FALSE, is.robust = FALSE)

summary(model.NoInteraction)
```

The results indicate that there is no significant effect, in reference to Ind level and Session. 

```{r}
#Response variable 
# response_variable <- "II_ind"

# Data to model
data_modified_ind <- ind_data %>%
  select(params$dependent_response_ind,
         Target, 
         SessionOrder, 
         Team, 
         Player_ID) %>%
  mutate(sqrt.value = sqrt(ifelse(.data[[params$dependent_response_ind]] < 0, 0, .data[[params$dependent_response_ind]]))) # Some fo the time remaining vaules are negative when the should be zero. I want to make sure those values are zero

# response_variable <- "sqrt.value"
data_focus_ind <- data_modified_ind

# Generate models with variable response
model.NoInteraction <- model_data_Target_Session(df = data_focus_ind, dependent =  "sqrt.value", model.type =  "NoInteraction", is.team = FALSE, is.robust = FALSE)

emmeans(model.NoInteraction, list(pairwise ~ Target), adjust = "tukey")
```

Results show no significant difference among the Target levels. 

```{r}
#Response variable 
# response_variable <- "II_ind"

# Data to model
data_modified_ind <- ind_data %>%
  select(params$dependent_response_ind,
         Target, 
         SessionOrder, 
         Team, 
         Player_ID) %>%
  mutate(sqrt.value = sqrt(ifelse(.data[[params$dependent_response_ind]] < 0, 0, .data[[params$dependent_response_ind]]))) # Some fo the time remaining vaules are negative when the should be zero. I want to make sure those values are zero

# response_variable <- "sqrt.value"
data_focus_ind <- data_modified_ind

# Generate models with variable response
model.NoInteraction <- model_data_Target_Session(df = data_focus_ind, dependent =  "sqrt.value", model.type =  "NoInteraction", is.team = FALSE, is.robust = FALSE)

emmeans(model.NoInteraction, list(pairwise ~ SessionOrder), adjust = "tukey")
```

The results show no significant difference between the session levels. 

##### Summary / Reflection

Overall, the model showed no unexpected or exciting significance. There was a lack of significance when examining the session order variable.

# References
