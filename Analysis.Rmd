---
title: "Dissertation Analysis"
author: "Jamiahus Walton"
bibliography: bibliography.bib
output:
  html_document: default
  pdf_document: 
  word_document: 
csl: apa.csl
Date: '2019-02-01'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Tips for formatting in RMarkdown
# Link: https://monashbioinformaticsplatform.github.io/2017-11-16-open-science-training/topics/rmarkdown.html

# Equations
# Link: https://www.calvin.edu/~rpruim/courses/s341/S17/from-class/MathinRmd.html

# Packages for data analysis
library(tidyverse)
library(lme4)
library(lmerTest)
library(emmeans)
library(svMisc)
library(MuMIn)
library(modelr)
library(sjstats)
library(knitr)
library(kableExtra)

# Functions used is documents ----
remove_measures_with_given_value <- function(data_set, col_name, value){
  rows_to_move <- which(as.vector(data_set[,col_name]) == value) 
  
  return(data_set[-rows_to_move,])
}

# Factor columns that need it.
re_factor_columns <- function(userData, columnNames){
  factorData <- userData
  for(column in columnNames){
    print(column)
    factorData[,column] <- factor(factorData[,column])
  }
  return(factorData)
}

# Model the data for the team level analysis ----
model_data_Target_Session <- function(df, dependent, model.type, is.team){
  
  if(is.team){
    if(model.type == "null"){
      lmer(data = df, as.formula(paste(dependent,"~ 1 + (1|Team)")))
    } else if(model.type == "All"){
      lmer(data = df, as.formula(paste(dependent,"~ Target * SessionOrder + (1|Team)")))
    } else if(model.type == "NoInteraction"){
      lmer(data = df, as.formula(paste(dependent,"~ Target + SessionOrder + (1|Team)")))
    } else if(model.type == "NoInteraction_NoTarget"){
      lmer(data = df, as.formula(paste(dependent,"~ SessionOrder + (1|Team)")))
    } else if(model.type == "NoInteraction_NoSession"){
      lmer(data = df, as.formula(paste(dependent,"~ Target + (1|Team)")))
    } else{
      stop("Model.type not supported")
    }
  } else {
    # Run this code if individual level model
    if(model.type == "null"){
      lmer(data = df, as.formula(paste(dependent,"~ 1 + (1|Team) + (1| Player_ID)")))
    } else if(model.type == "All"){
      lmer(data = df, as.formula(paste(dependent,"~ Target * SessionOrder + (1|Team) + (1| Player_ID)")))
    } else if(model.type == "NoInteraction"){
      lmer(data = df, as.formula(paste(dependent,"~ Target + SessionOrder + (1|Team) + (1| Player_ID)")))
    } else if(model.type == "NoInteraction_NoTarget"){
      lmer(data = df, as.formula(paste(dependent,"~ SessionOrder + (1|Team) + (1| Player_ID)")))
    } else if(model.type == "NoInteraction_NoSession"){
      lmer(data = df, as.formula(paste(dependent,"~ Target + (1|Team) + (1| Player_ID)")))
    } else{
      stop("Model.type not supported")
    }
  }
}

#Folder locations ----
main_work_directory_name <- main_work_directory_name <- "C:\\Users\\jamia\\Box\\TMET2\\DATA TMET2\\Data_And_Calcuations\\Raw Data\\"
database_folder_name <- "Database"
file_name_output <- "team_player_aggragate_stats.csv"
folder_location_database <- paste(main_work_directory_name, database_folder_name, sep = "")
aggregate_folder_location <- paste(folder_location_database,"\\", file_name_output, sep = "") #This will combine the final file name and the desiered folder location

# Read aggregaate data ----
my_aggregate_data <- read.csv(file =  aggregate_folder_location)

clean_aggregate_data_stats <- remove_measures_with_given_value(data_set =  my_aggregate_data, col_name = "Condition", value = "A") # without none condition

# Re factor the columns
columns_to_refactor <- c("SessionOrder", 
                         "Team", 
                         "Player_ID", 
                         "Condition", 
                         "Dominate.Strategy", 
                         "Condition", 
                         "Target",
                         "Confident_team_comm_important_details_quickly")
clean_aggregate_data_stats <- re_factor_columns(clean_aggregate_data_stats, columns_to_refactor)

# What is the N for Teams ----
N_teams <- length(levels(factor(clean_aggregate_data_stats$Team)))

# What is the N for Inds ----
N_ind <- length(levels(factor(clean_aggregate_data_stats$Player_ID) ))

# Team data set ----
team_data <- clean_aggregate_data_stats %>%
  filter(Player == 1)

# Individual data set ----
ind_data <- clean_aggregate_data_stats

```

## Purpose

The purpose of this document is to record the data analysis for my Dissertation.

## Experimental Design

This experiment is a within-subject experimental design. The primary variable was the feedback condition (i.e., Target). There were four feedback conditions; None, Individual, Team, and Indvidiaul_Team. Each team experienced each condition. The first condition for each group was the none condition. The remaining three conditions were counterbalanced. For example, the condition order for team 7 is the following: None, Ind, Team, Ind_Team. The condition order for group 8 is the following: None, Team, Individual, Individual_Team. 

## Data Description

I collected data from **`r N_ind`** participants that formed **`r N_teams`** teams. Below is a sample of the data for the main metrics
```{r main_metrics_table, echo=FALSE}
knitr::kable(
  clean_aggregate_data_stats[1:5,c("TeamScore", 
                           "IndividualScore", 
                           "CI_team", 
                           "CI_ind", 
                           "II_team", 
                           "II_ind", 
                           "ERROR_team_unique", 
                           "ERROR_ind_unique", 
                           "ERROR_team_total",
                           "ERROR_ind_total")]
)
```

## Research Question

This research attempts to answer the following question: How will teams' performance change if given feedback that displays indicators based on individual performance, team performance, or both?

## Explore

In this section, I seek to discover answers, visually, that answer the research question mentioned above.

### Q: Is there exciting variation among the *time remaining* that will help me understand the influence of the feedback condition?

#### Team

```{r}
dependent_response_team <- "timeRemaining_team"
y_label_team <- "Count"
x_label_team <- "Time Remaining"
title_response_team <- "Distrabution of Time Remaining (Team)"

plot_data_team <- team_data %>%
  select(dependent_response_team, Target)

ggplot(data = plot_data_team) + 
  geom_histogram(aes_string(x = dependent_response_team), bins = 30) +
  labs(title = title_response_team, x = x_label_team, y = y_label_team)
```

Overall, the distribution of the time remaining is skewed to the left. This skew tells me that most of the teams had around 50 seconds left, or less, at the end of each session. 

```{r}
dependent_response_team <- "timeRemaining_team"
y_label_team <- "Count"
x_label_team <- "Target"
title_response_team <- "Distrabution of Time Remaining (Team)"

plot_data_team <- team_data %>%
  select(dependent_response_team, Target)

ggplot(data = plot_data_team) + 
  geom_histogram(aes_string(x = dependent_response_team), bins = 25) +
  facet_grid(. ~ Target) +
  labs(title = title_response_team, x = x_label_team, y = y_label_team)
```

The skewed to the left pattern continues when grouping the time remaining by the feedback conditions. Most of the teams seem to have about 50 seconds remaining when the task was completed. 

*Reflection:* The skewness in the time remaining data at the team level. This skewness suggests that most of the teams had about the same amount of time remaining at the end of the session (50 or 40 seconds). 

#### Individual

```{r}
dependent_response_ind <- "timeRemaining_ind"
y_label_ind <- "Count"
x_label_ind <- "Time Remaining"
title_response_ind <- "Distrabution of Time Remaining (Individual)"

plot_data_ind <- ind_data %>%
  select(dependent_response_ind, Target)

ggplot(data = plot_data_ind) + 
  geom_histogram(aes_string(x = dependent_response_ind), bins = 40) +
  labs(title = title_response_ind, x = x_label_ind, y = y_label_ind)
```

Overall, the time remaining at the individual level is skewed to the left. This skewness tells me that most of the participants had 50 seconds or left at the end of the sessions. I also notice that there are a number of data points that are distributed from about 60 to 350. Are there similar characteristics among the teams that have more than 50 seconds remaining at the end of the sessions?

```{r}
dependent_response_ind <- "timeRemaining_ind"
y_label_ind <- "Count"
x_label_ind <- "Time Remaining"
title_response_ind <- "Distrabution of Time Remaining (Individual)"

plot_data_ind <- ind_data %>%
  select(dependent_response_ind, Target)

ggplot(data = plot_data_ind) + 
  geom_histogram(aes_string(x = dependent_response_ind), bins = 30) +
  facet_grid(. ~ Target) +
  labs(title = title_response_ind, x = x_label_ind, y = y_label_ind)
  
```

The distribution for each condition is similar to the overall condition. This similarity tells me that most individuals finished with about 50 seconds or so left at the end of each session. It seems as though we can say the high performing individuals finished with over 50 seconds or so left at the end of the session. Do high performing individuals have similar characteristics?

*Reflection:* The distribution is similar to the distribution of the time remaining at the team level. The distribution was skewed to the left and most of the time remaining at the end of the session was about 50 or 60 seconds  
  
  
#### Summary / Reflection

Overall, the data looks to be skewed to the left. According to the count at the individual and team level, the teams and players that finished with more than 50 seconds or so left at the end of the session were high performing teams. There did not seem to be any obvious pattern when grouping the data by Feedback conditions. Maybe the feedback conditions influenced the amount of time remaining depending on their experience (i.e., session order)? 

### Q: Is there exciting variation among the *time remaining* that explains how the feedback conditions influence the time remaining when session order is taken into consideration?

#### Team

```{r}
dependent_response_team <- "timeRemaining_team"
y_label_team <- "Count"
x_label_team <- "Time Remaining"
title_response_team <- "Distrabution of Time Remaining (Team)"

plot_data_team <- team_data %>%
  select(dependent_response_team, Target, SessionOrder)

ggplot(data = plot_data_team) + 
  geom_histogram(aes_string(x = dependent_response_team), bins = 30) +
  labs(title = title_response_team, x = x_label_team, y = y_label_team) +
  facet_grid( SessionOrder ~ Target)
```

It looks like the time remaining for teams in the individual feedback condition did not change the amount of time remaining at the end of the session. The lack of change is unusual because I would expect the distribution to spread over time because teams would get better and they would complete the task quicker.   
  
It looks like the time remaining for the individual_team condition seems to spread over time. Meaning that the teams were completing the task faster the more they completed the task. I would not be surprised if the Individual_Team condition were trending to significant.  
  
  
It looks like the distribution of the amount of time remaining at the end of the session in the team feedback condition starts to spread over time. This distrabution is what I would expect to see.

*Reflection:* I would expect to see the distribution of time remaining spread over time because the teams would learn the task and get better at the task. This pattern is not followed in the individual condition. The distribution of the time remaining in the individual condition does not seem to spread over time. The amount of time remaining is consistent no matter what session order (i.e., 2,3, or 4) they are in. This consistency would suggest that giving individual performance metrics does not influence the amount of time remaining at the end of the session for a team. 

#### Individual

```{r}
dependent_response_ind <- "timeRemaining_ind"
y_label_ind <- "Count"
x_label_ind <- "Time Remaining"
title_response_ind <- "Distrabution of Time Remaining (Individual)"

plot_data_ind <- ind_data %>%
  select(dependent_response_ind, Target, SessionOrder)

ggplot(data = plot_data_ind) + 
  geom_histogram(aes_string(x = dependent_response_ind), bins = 30) +
  facet_grid(SessionOrder ~ Target) +
  labs(title = title_response_ind, x = x_label_ind, y = y_label_ind)
```

It looks like the distribution of the time remaining in the individual condition does not spread over time. This lack of spread tells me that the individuals were not getting faster over time in the individual feedback condition. It looks like the spread of the time remaining in the Indivdual_team condition does spread over time. There is a more obvious spread from session 3 to session 4. It looks like the time remaining in the team condition does spread over time. This is what I would expect. 

*Reflection:* I am getting the sense that the individual condition did not influence how quickly the participants completed the session. In other words, giving the individual feedback on performance metrics did not encourage the participants to move faster through the session. However, it looks like the spread over the time remaining increases when given team or ind_team feedback. This tells me that teams are more likely to move through the task quicker if given individual_team or team feedback, not individual feedback. 


#### Summary / Reflection

Overall, the distribution is telling me that over time, teams move through the task quicker when given team or ind_team feedback but not individual feedback. This suggests that if I looked at the fourth session and group the data by the feedback conditions, I would see that the time remaining in the individual_team and Team condition would be significantly different from the time remaining in the individual condition.


### Q: Is there an *interaction* between the Target and Session Order for the *time remaining*?

I am interested in this question for modeling purposes. Right now I want to know if I need to include the interaction between Target and Session Order. 

#### Team

```{r fig.width= 10}
dependent_response_team <- "timeRemaining_team"
y_label_team <- "Time Remaining"
x_label_team <- "Target"
title_response_team <- "Time Remaining (Team) Vs. Target"
value_threshold <- 120

plot_data_team <- team_data %>%
  select(Target, SessionOrder, dependent_response_team, Team) %>%
  mutate(rank_order = -rank(team_data[[dependent_response_team]])) %>%
  mutate(above_value_threshold = .data[[dependent_response_team]] > value_threshold)

names <- ifelse(plot_data_team[,"above_value_threshold"], as.character( plot_data_team[,"Team"]), "")

ggplot(data = plot_data_team, 
       aes(x = factor(SessionOrder), 
                  y = .data[[dependent_response_team]], 
                  fill = Team, group = rank_order,
                  label = names )) +
  geom_text(position = position_dodge(1), vjust = 0, aes(y = .data[[dependent_response_team]] + 10), check_overlap = FALSE) +
  geom_bar(stat = "identity", position = "dodge") + 
  facet_grid(. ~ Target) + 
  guides(fill = FALSE) +
  labs(y = y_label_team, x = x_label_team, title = title_response_team, fill = "Teams")
```

Visually, the first thing that jumps out to me that there seem to be a few outliers that may be influencing the results. The teams that are labeled had more than 120 seconds (2 minutes) remaining at the end of the session. Let's call a "fast" a team that has more than 120 seconds left at the end of the session. The groups that are labeled in all the conditions (Target levels) are team 26, 45, 13 (there may be more I am missing). Some of these teams data may be outliers. 

*Reflection:* This figure tells me that I may need to consider removing these teams because they may be outliers. 


```{r}
dependent_response_team <- "timeRemaining_team"
y_label_team <- "Time Remaining"
x_label_team <- "Target"
title_response_team <- "Time Remaining (Team) Vs. Target"

plot_data_team <- team_data %>%
  select(Target, SessionOrder, timeRemaining_team) %>%
  group_by(SessionOrder, Target) %>%
  summarise(timeRemaining_teamAverage = mean(timeRemaining_team), 
            Stdv =sd(timeRemaining_team), n = length(timeRemaining_team), 
            StEr = sd(timeRemaining_team) / sqrt(length(timeRemaining_team)))

ggplot(data = plot_data_team, aes(x = Target, y = timeRemaining_teamAverage, color = SessionOrder, shape = SessionOrder)) +
  geom_point(size = 3) +
  geom_line(aes(group=SessionOrder, color = SessionOrder)) + 
  geom_errorbar(aes(ymin = timeRemaining_teamAverage - StEr, ymax = timeRemaining_teamAverage + StEr), width = 0.2) +
  labs(y = y_label_team, x = x_label_team, title = title_response_team, color = "Session", shape = "Session")
```

Visually, there appears to be some level of interaction between Target and SessionOrder for the time remaining. The interaction does not seem like a strong interaction. The graph suggests that the average time remaining at the end of the session increases over time. The increase is particularly noticeable in the Ind_Team condition going from session 3 to session 4.  In other words, when given team feedback, the amount of time remaining at the end of each session increases faster. 

*Reflection:* There seems to be some level of interaction but I am getting the sense that it is not a strong interaction. I'll have to run statistical tests to examine the strength of the effect if there is an interaction effect. 

```{r}
dependent_response_team <- "timeRemaining_team"
y_label_team <- "Time Remaining"
x_label_team <- "Target"
title_response_team <- "Time Remaining (Team) Vs. Session Order"

plot_data_team <- team_data %>%
  select(Target, SessionOrder, timeRemaining_team) %>%
  group_by(SessionOrder, Target) %>%
  summarise(timeRemaining_teamAverage = mean(timeRemaining_team), 
            Stdv =sd(timeRemaining_team), n = length(timeRemaining_team), 
            StEr = sd(timeRemaining_team) / sqrt(length(timeRemaining_team)))

ggplot(data = plot_data_team, aes(x = SessionOrder , y = timeRemaining_teamAverage, color = Target, shape = Target)) +
  geom_point(size = 3) +
  geom_line(aes(group=Target, color = Target)) + 
  geom_errorbar(aes(ymin = timeRemaining_teamAverage - StEr, ymax = timeRemaining_teamAverage + StEr), width = 0.2) +
  labs(y = y_label_team, x = x_label_team, title = title_response_team, color = "Session", shape = "Session")
```

There appears to be an interaction between the Target and Session Order variable. This figure tells me that over time the amount of time remaining at the end of each session increases over time. This figure tells me that in the different session orders, the amount of time remaining at the end of each session is roughly the same. However, over time, the amount of time remaining at the end of the session changes differently depending on the session. 
  
  
The individual session steadily improves over time. 

The Indivdual_Team session has a small improvement from session 2 to session 3, but there is a substantial increase from session 3 to session 4. This tells me that for some reason there was little change between session 2 and session 3, but something happened that caused a major improvement from session 3 to session 4. 

The team session showed a substantial increase from session 2 to 3 but a small improvement from session 3 to session 4. This suggests that for some reason there was a major improvement between session 2 and session 3, but then there was little gain between session 3 and session 4. This could mean that the feedback was no longer useful between 3 and 4 or that the teams reached their highest performance. 

*Reflection:* I am getting the session that the team condition encourage teams to move quicker through the session. There was a substantial increase in the amount of time remaining at the end of the session in the team condition when moving from session 2 to session 3. I am also getting the sense that the individual_team feedback condition may be encouraging a team to move quicker through the task as well. However, it looks like the effect of the inddividual_team feedback takes longer to take effect. Even so, there amount of time remaining at the end of the session ended up being about the same after four sessions in the individual_team and the team condition. 


#### Individual

```{r}
dependent_response_ind <- "timeRemaining_ind"
y_label_ind <- "Time Remaining"
x_label_ind <- "Target"
title_response_ind <- "Time Remaining (Individual) Vs. Target"

plot_data_ind <- ind_data %>%
  select(Target, SessionOrder, dependent_response_ind) %>%
  group_by(SessionOrder, Target) %>%
  summarise(Average = mean(.data[[dependent_response_ind]]), 
            Stdv =sd(.data[[dependent_response_ind]]), 
            n = length(.data[[dependent_response_ind]]), 
            StEr = sd(.data[[dependent_response_ind]]) / sqrt(length(.data[[dependent_response_ind]])))

ggplot(data = plot_data_ind, aes(x = Target, y = Average, color = SessionOrder, shape=SessionOrder)) +
  geom_point(size = 3) +
  geom_line(aes(group=SessionOrder, color = SessionOrder)) + 
  geom_errorbar(aes(ymin = Average - StEr, ymax = Average + StEr), width = 0.2) +
  labs(y = y_label_ind, x = x_label_ind, title = title_response_ind, fill = "Players")
```

There appears to be an interaction between Target and Session Order. Overall, the amount of time at the end of the session increases over time. It looks like there is a considerable increase in the amount of time remaining in the Team condition. This substantial increase suggests that giving team feedback results in teams moving faster. It looks like there is something exciting happening in the team and individual_team condition. In the individual condition, there is a steady increase in the amount of time remaining. In the Individual_Team condition, there was little to no change in the time remaining between session 2 and 3. 

*Reflection:* I am getting the sense that something is happening with the individual_team and the team condition. For some reason, there are these large increases in the time remaining. 

```{r}
dependent_response_ind <- "timeRemaining_ind"
y_label_ind <- "Time Remaining"
x_label_ind <- "Target"
title_response_ind <- "Time Remaining (Individual) Vs. Target"

plot_data_ind <- ind_data %>%
  select(Target, SessionOrder, dependent_response_ind) %>%
  group_by(SessionOrder, Target) %>%
  summarise(Average = mean(.data[[dependent_response_ind]]), 
            Stdv =sd(.data[[dependent_response_ind]]), 
            n = length(.data[[dependent_response_ind]]), 
            StEr = sd(.data[[dependent_response_ind]]) / sqrt(length(.data[[dependent_response_ind]])))

ggplot(data = plot_data_ind, aes(x = SessionOrder, y = Average, color = Target, shape=Target)) +
  geom_point(size = 3) +
  geom_line(aes(group=Target, color = Target)) + 
  geom_errorbar(aes(ymin = Average - StEr, ymax = Average + StEr), width = 0.2) +
  labs(y = y_label_ind, x = x_label_ind, title = title_response_ind, fill = "Players")
```

There seems to be an interaction between the session order and the target variable. 

In the individual condition, there is a steading increase in the time remaining at the individual level. 

In the team condition, there is a large improvement from session 2 to session 3 but little to no improvement from session 3 to session 4. 

In the individual_team condition, there is little to no improvement from session 2 to session 3 but a large improvement from session 3 to session 4. 

*Reflection:* There is a session that something interesting is going on with the individual_team and team conditions. It seems as though the effect of the team condition happen quicker than the impact of the individual_team condition

#### Summary / Reflection

I am getting the sense that there is something interesting happening with the individual_team condition and team condition. For some reason, the positive effect (i.e., the large increase in the time remaining at the end of the session) happens quicker than the positive effect from the individual_team condition. More exploration is needed to understand why this apparent effect is happening. Some statical analysis is necessary to determine the strength of this effect if it exists.


### Q: Is there an interaction between the Target and Session Order for the *time remaining* that is statistically significant?

I am interested in determining if a model of the data should include an interaction between the Target and Session Order variable. When fitting a model, we need to look at the residuals to check assumptions [@Galwey2014]. 

* The residuals should have an approximately normal distribution (i.e., a bell curve) when plotted on a histogram
* A fitted-value plot should show an almost constant width when viewed from left to right
* The points on a normal plot should lie on an almost straight line from the bottom left to the top right

There are a few steps I will take before testing the assumptions. First, I fit the model the data using multiple models. Second, I will compare those models to the null model. Second, I will pick the models that are worth exploring further. Third, I will evaluate the effect size ($R^2$) of the fixed effect and random effect variables using a method by Nakagawa and Schielzeth (@Nakagawa2013). Lastly, I will analyze the assumptions for the residuals. 

A note on the effect size ($R^2$). This method generates two types of ($R^2$) values called marginal ($R^2$) ($R_{m}^2$) and conditional ($R^2$) ($R_{c}^2$). The $R_{m}^2$ describes how the variance is described by the fixed effect variables (feedback condition and session order) while the $R_{c}^2$ describes how both the variance is described by both the fixed and random effect variables

#### Full Models Used for Team and Individual

The next two sections below describe the full model for team and individual level analysis. Eight models were fitted and then compared. Eight other models are a subset of the full model (including a null model that has no fixed effect variables). One or two fixed effects are removed from the full model. 

##### Team Full Model

$$ y_{ijt} = \mu + \alpha_{i} + \beta_{j} + \alpha_{i} \beta_{j} + \gamma_{t} +   \epsilon_{ijt}$$ 

Where $y_{ijt}$ is the response variable (e.g., team score), $\mu$ is the baseline (or intercept), $\alpha_{i}$ is the fixed effect for the ith feedback target category, $\beta_{j}$ is the fixed effect for the jth session order, $\gamma_{t}$ is the random effect for the tth team, $ \alpha_{i} \beta_{j}$ is the fixed effect of the interaction between the feedback target and session order, and $\epsilon_{ijt}$ is the residual for the model. 

##### Individual Team Full Model

$$ y_{ijtp} = \mu + \alpha_{i} + \beta_{j} + \alpha_{i} \beta_{j} + \gamma_{t} + \theta_{p} + \epsilon_{ijtp}$$ 

Where $y_{ijtp}$ is the response variable (e.g., team score), $\mu$ is the baseline (or intercept), $\alpha_{i}$ is the fixed effect for the ith feedback target category, $\beta_{j}$ is the fixed effect for the jth session order, $\gamma_{t}$ is the random effect for the tth team, $\theta_{p}$ is the random effect for the pth individual, $ \alpha_{i} \beta_{j}$ is the fixed effect of the interaction between the feedback target and session order, and $\epsilon_{ijtp}$ is the residual for the model.

#### Team

```{r message=FALSE}
# Data to fit
data_modified_team <- team_data %>%
  select(TeamScore,
         timeRemaining_team,
         Target, 
         SessionOrder, 
         Team)

# Generate models with variable response
response_variable <- "timeRemaining_team"
data_focus_team <- data_modified_team
model.null <- model_data_Target_Session(df = data_focus_team, dependent =  response_variable, model.type =  "null", is.team = TRUE)
model.All <- model_data_Target_Session(df = data_focus_team, dependent =  response_variable, model.type =  "All", is.team = TRUE)
model.NoInteraction <- model_data_Target_Session(df = data_focus_team, dependent =  response_variable, model.type =  "NoInteraction", is.team = TRUE)
model.NoInteraction.NoTarget <- model_data_Target_Session(df = data_focus_team, dependent =  response_variable, model.type =  "NoInteraction_NoTarget", is.team = TRUE)
model.NoInteraction.NoSession <- model_data_Target_Session(df = data_focus_team, dependent =  response_variable, model.type =  "NoInteraction_NoSession", is.team = TRUE)


comparision.results <- anova(model.null, 
                             model.All, 
                             model.NoInteraction,
                             model.NoInteraction.NoTarget,
                             model.NoInteraction.NoSession)

knitr::kable(comparision.results)

# Effect size (R^2)

kable(r.squaredGLMM(model.NoInteraction.NoTarget),
      caption = "Table: Effect size for for *No Interaction and No Target*") %>%
   kable_styling(full_width = F)

kable(r.squaredGLMM(model.NoInteraction),
      caption = "Table: Effect size for for *No Interaction*") %>%
   kable_styling(full_width = F)

```

The following models were significantly different from the null model: model.NoInteraction.NoTarget, model.NoInteraction. 

model.NoInteraction.NoTarget: Session order is the only fixed effect in this model. 

model.NoInteraction: Session order and target are the fixed effects in this model.

*Reflection:* Both of the models that are significantly different from the null model are missing the interaction effect. This tells me that the interaction does not have a strong impact when modeling the main effects.

Each model has a similar conditional effect size. As well, there was no noticeable difference for the marginal effect sizes for each model either. It seems as though all three models have similar in effectiveness. No model is better than the others. 


#### Individual

```{r, message=FALSE}
# Data to model
data_modified_ind <- ind_data %>%
  select(timeRemaining_ind,
         Target, 
         SessionOrder, 
         Team, 
         Player_ID)

response_variable <- "timeRemaining_ind"
data_focus_ind <- data_modified_ind
model.null <- model_data_Target_Session(df = data_focus_ind, dependent =  response_variable, model.type =  "null", is.team = FALSE)
model.All <- model_data_Target_Session(df = data_focus_ind, dependent =  response_variable, model.type =  "All", is.team = FALSE)
model.NoInteraction <- model_data_Target_Session(df = data_focus_ind, dependent =  response_variable, model.type =  "NoInteraction", is.team = FALSE)
model.NoInteraction.NoTarget <- model_data_Target_Session(df = data_focus_ind, dependent =  response_variable, model.type =  "NoInteraction_NoTarget", is.team = FALSE)
model.NoInteraction.NoSession <- model_data_Target_Session(df = data_focus_ind, dependent =  response_variable, model.type =  "NoInteraction_NoSession", is.team = FALSE)

comparision.results <- anova(model.null, 
                             model.All, 
                             model.NoInteraction, 
                             model.NoInteraction.NoTarget,
                             model.NoInteraction.NoSession)
knitr::kable(comparision.results)

# Effect size (R^2)

kable(r.squaredGLMM(model.NoInteraction.NoTarget),
      caption = "Table: Effect size for for *No Interaction and No Target*") %>%
   kable_styling(full_width = F)

kable(r.squaredGLMM(model.NoInteraction),
      caption = "Table: Effect size for for *No Interaction*") %>%
   kable_styling(full_width = F)
```

The following models were significantly different from the null model: model.NoInteraction.NoTarget, model.NoInteraction.

model.NoInteraction.NoTarget: Session order is the only fixed effect in this model.

model.NoInteraction: Session order and target are the fixed effects in this model.

*Reflection:* In both of the models that are significantly different from the null model do not include the interaction effect.

The Target effect sees to be somewhat important when considered with session order (i.e., model.NoInteraction). Though it is not significant when considered by itself. 


#### Summary / Reflection

The models that were significantly different from the null model were model.NoInteraction.NoTarget and model.NoInteraction. 

Overall, these models (model.NoInteraction.NoTarget, model.NoInteraction) seemed to fit the data best. These collections of models tell me that session order effect is important because it is in both models. It also tells me that the Target effect is important when considered with session order and that the interaction is not important because it is not in either of the models.

It seems as though the answer to the original questions about the interaction is that there seems to be no statistically significant effect from the interaction between the session order and the target. The fact that that there is no statistically significant effect from the interaction of the session order and target on the individual and team level, suggests that there is no interaction between the variables.  

My next step is to fit the models and see what I can learn from these models. Are any of the effect in these models significantly different from zero?

# References
