---
title: "Dissertation Analysis"
author: "Jamiahus Walton"
bibliography: bibliography.bib
output:
  html_document: default
  pdf_document: 
  word_document: 
csl: apa.csl
Date: '2019-02-01'
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Tips for formatting in RMarkdown
# Link: https://monashbioinformaticsplatform.github.io/2017-11-16-open-science-training/topics/rmarkdown.html

# Equations
# Link: https://www.calvin.edu/~rpruim/courses/s341/S17/from-class/MathinRmd.html

# Create awesome HTML table with knitr::kableand kableExtra
# LinkL https://haozhu233.github.io/kableExtra/awesome_table_in_html.html

# Examples of how to use the ggrepel package
# Link: https://cran.r-project.org/web/packages/ggrepel/vignettes/ggrepel.html#examples

# Packages for data analysis
library(tidyverse)
library(lme4)
library(lmerTest)
library(emmeans)
library(svMisc)
library(MuMIn)
library(modelr)
library(sjstats)
library(robustlmm)
library(ggrepel)
library(knitr)
library(kableExtra)

# Functions used is documents ----
remove_measures_with_given_value <- function(data_set, col_name, value){
  rows_to_move <- which(as.vector(data_set[,col_name]) == value) 
  
  return(data_set[-rows_to_move,])
}

# Factor columns that need it.
re_factor_columns <- function(userData, columnNames){
  factorData <- userData
  for(column in columnNames){
    print(column)
    factorData[,column] <- factor(factorData[,column])
  }
  return(factorData)
}

# Model the data for the team level analysis ----
model_data_Target_Session <- function(df, dependent, model.type, is.team, is.robust){
  
  if(is.team){
    if(model.type == "null" && !is.robust){
      lmer(data = df, as.formula(paste(dependent,"~ 1 + (1|Team)")))
    } else if(model.type == "All"){
      lmer(data = df, as.formula(paste(dependent,"~ Target * SessionOrder + (1|Team)")))
    } else if(model.type == "NoInteraction" && !is.robust){
      lmer(data = df, as.formula(paste(dependent,"~ Target + SessionOrder + (1|Team)")))
    } else if(model.type == "NoInteraction_NoTarget" && !is.robust){
      lmer(data = df, as.formula(paste(dependent,"~ SessionOrder + (1|Team)")))
    } else if(model.type == "NoInteraction_NoSession" && !is.robust){
      lmer(data = df, as.formula(paste(dependent,"~ Target + (1|Team)")))
    } else if(model.type == "null" && is.robust){
      rlmer(data = df, as.formula(paste(dependent,"~ 1 + (1|Team)")))
    } else if(model.type == "All" && is.robust){
      rlmer(data = df, as.formula(paste(dependent,"~ Target * SessionOrder + (1|Team)")))
    } else if(model.type == "NoInteraction" && is.robust){
      rlmer(data = df, as.formula(paste(dependent,"~ Target + SessionOrder + (1|Team)")))
    } else if(model.type == "NoInteraction_NoTarget" && is.robust){
      rlmer(data = df, as.formula(paste(dependent,"~ SessionOrder + (1|Team)")))
    } else if(model.type == "NoInteraction_NoSession" && is.robust){
      rlmer(data = df, as.formula(paste(dependent,"~ Target + (1|Team)")))
    } else{
      stop("Model.type not supported")
    }
  } else {
    # Run this code if individual level model
    if(model.type == "null" && !is.robust){
      lmer(data = df, as.formula(paste(dependent,"~ 1 + (1|Team) + (1| Player_ID)")))
    } else if(model.type == "All" && !is.robust){
      lmer(data = df, as.formula(paste(dependent,"~ Target * SessionOrder + (1|Team) + (1| Player_ID)")))
    } else if(model.type == "NoInteraction" && !is.robust){
      lmer(data = df, as.formula(paste(dependent,"~ Target + SessionOrder + (1|Team) + (1| Player_ID)")))
    } else if(model.type == "NoInteraction_NoTarget" && !is.robust){
      lmer(data = df, as.formula(paste(dependent,"~ SessionOrder + (1|Team) + (1| Player_ID)")))
    } else if(model.type == "NoInteraction_NoSession"){
      lmer(data = df, as.formula(paste(dependent,"~ Target + (1|Team) + (1| Player_ID)")))
    } else if(model.type == "null" && is.robust){
      rlmer(data = df, as.formula(paste(dependent,"~ 1 + (1|Team) + (1| Player_ID)")))
    } else if(model.type == "All" && is.robust){
      rlmer(data = df, as.formula(paste(dependent,"~ Target * SessionOrder + (1|Team) + (1| Player_ID)")))
    } else if(model.type == "NoInteraction" && is.robust){
      rlmer(data = df, as.formula(paste(dependent,"~ Target + SessionOrder + (1|Team) + (1| Player_ID)")))
    } else if(model.type == "NoInteraction_NoTarget" && is.robust){
      rlmer(data = df, as.formula(paste(dependent,"~ SessionOrder + (1|Team) + (1| Player_ID)")))
    } else if(model.type == "NoInteraction_NoSession" && is.robust){
      rlmer(data = df, as.formula(paste(dependent,"~ Target + (1|Team) + (1| Player_ID)")))
    } else{
      stop("Model.type not supported")
    }
  }
}

#Folder locations ----
figure_directory <- "C:\\Users\\jamia\\Box\\TMET2\\DATA TMET2\\Data_And_Calcuations\\Figures"
main_work_directory_name <- main_work_directory_name <- "C:\\Users\\jamia\\Box\\TMET2\\DATA TMET2\\Data_And_Calcuations\\Raw Data\\"

database_folder_name <- "Database"
file_name_output <- "team_player_aggragate_stats.csv"
folder_location_database <- paste(main_work_directory_name, database_folder_name, sep = "")
aggregate_folder_location <- paste(folder_location_database,"\\", file_name_output, sep = "") #This will combine the final file name and the desiered folder location

# Read aggregaate data ----
my_aggregate_data <- read.csv(file =  aggregate_folder_location)

clean_aggregate_data_stats <- remove_measures_with_given_value(data_set =  my_aggregate_data, col_name = "Condition", value = "A") # without none condition

# Re factor the columns
columns_to_refactor <- c("SessionOrder", 
                         "Team", 
                         "Player_ID", 
                         "Condition", 
                         "Dominate.Strategy", 
                         "Condition", 
                         "Target",
                         "Confident_team_comm_important_details_quickly")
clean_aggregate_data_stats <- re_factor_columns(clean_aggregate_data_stats, columns_to_refactor)

# What is the N for Teams ----
N_teams <- length(levels(factor(clean_aggregate_data_stats$Team)))

# What is the N for Inds ----
N_ind <- length(levels(factor(clean_aggregate_data_stats$Player_ID) ))

# Team data set ----
team_data <- clean_aggregate_data_stats %>%
  filter(Player == 1)

# Individual data set ----
ind_data <- clean_aggregate_data_stats

```

## Purpose

The purpose of this document is to record the data analysis for my Dissertation.

## Experimental Design

This experiment is a within-subject experimental design. The primary variable was the feedback condition (i.e., Target). There were four feedback conditions; None, Individual, Team, and Ind_Team Each team experienced each condition. The first condition for each group was the None condition. The remaining three conditions were counterbalanced. For example, the condition order for team 7 is the following: None, Ind, Team, Ind_Team. The condition order for group 8 is the following: None, Team, Individual, Ind_Team. 

## Data Description

I collected data from **`r N_ind`** participants that formed **`r N_teams`** teams. Below is a sample of the data for the main metrics

```{r main_metrics_table, echo=FALSE}
dt <- clean_aggregate_data_stats[1:5,c("TeamScore", 
                           "IndividualScore", 
                           "CI_team", 
                           "CI_ind", 
                           "II_team", 
                           "II_ind", 
                           "ERROR_team_unique", 
                           "ERROR_ind_unique", 
                           "ERROR_team_total",
                           "ERROR_ind_total")] 
dt %>%
  kable() %>%
  kable_styling()
```

## Research Question

This research attempts to answer the following question: *How will teams' performance change if given feedback that displays indicators based on individual performance, team performance, or both?*

## Exploratory Data Analysis

In this section, I seek to visually discover answers to the research question mentioned above.

### Q: Is there exciting variation among the *time remaining* metric that will help me understand the influence of the feedback condition?

#### Team

```{r}
dependent_response_team <- "timeRemaining_team"
y_label_team <- "Count"
x_label_team <- "Time Remaining"
title_response_team <- "Distribution of Time Remaining (Team)"
plot_name <- "Histogram_TimeRemaining_Team.png"
setwd(figure_directory)

plot_data_team <- team_data %>%
  select(dependent_response_team, Target)

ggplot(data = plot_data_team) + 
  geom_histogram(aes_string(x = dependent_response_team), bins = 30) +
  labs(title = title_response_team, x = x_label_team, y = y_label_team) +
  ggsave(filename = plot_name)
```

Overall, the distribution of the time remaining is skewed to the left. This skew tells me that most of the teams had around 50 seconds left, or less, at the end of each session. 

```{r}
dependent_response_team <- "timeRemaining_team"
y_label_team <- "Count"
x_label_team <- "Target"
title_response_team <- "Distribution of Time Remaining (Team)"
plot_name <- "Histogram_TimeRemaining_ByTarget_Team.png"
setwd(figure_directory)

plot_data_team <- team_data %>%
  select(dependent_response_team, Target)

ggplot(data = plot_data_team) + 
  geom_histogram(aes_string(x = dependent_response_team), bins = 25) +
  facet_grid(. ~ Target) +
  labs(title = title_response_team, x = x_label_team, y = y_label_team) +
  ggsave(filename = plot_name)

# Information about the N values in each condition
tableData <- team_data %>%
  group_by(Target) %>%
  summarise(N = length(.data[[dependent_response_team]]))

tableData %>%
  kable() %>%
  kable_styling()
```

The skewed to the left pattern continues when grouping the time remaining by the feedback conditions. Most of the teams seem to have about 50 seconds remaining when they completed the task 

*Reflection:* The skewness in the time remaining data at the team level centers around 50 seconds or so. This skewness suggests that most of the teams had about the same amount of time remaining at the end of the session (50 or 40 seconds). In other words, there is no obvious pattern visually. 

#### Individual

```{r}
dependent_response_ind <- "timeRemaining_ind"
y_label_ind <- "Count"
x_label_ind <- "Time Remaining"
title_response_ind <- "Distribution of Time Remaining (Individual)"
plot_name <- "Histogram_TimeRemaining_Ind.png"
setwd(figure_directory)

plot_data_ind <- ind_data %>%
  select(dependent_response_ind, Target)

ggplot(data = plot_data_ind) + 
  geom_histogram(aes_string(x = dependent_response_ind), bins = 40) +
  labs(title = title_response_ind, x = x_label_ind, y = y_label_ind) +
  ggsave(filename = plot_name)
```

Overall, the time remaining at the individual level is skewed to the left. This skewness tells me that most of the participants had 40 to 50 seconds remaining at the end of the sessions. I also notice that there are a number of data points distributed from about 60 to 350. Are there similar characteristics among the teams that have more than 50 seconds remaining at the end of the sessions?

```{r}
dependent_response_ind <- "timeRemaining_ind"
y_label_ind <- "Count"
x_label_ind <- "Time Remaining"
title_response_ind <- "Distribution of Time Remaining (Individual)"
plot_name <- "Histogram_TimeRemaining_ByTarget_Ind.png"
setwd(figure_directory)

plot_data_ind <- ind_data %>%
  select(dependent_response_ind, Target)

ggplot(data = plot_data_ind) + 
  geom_histogram(aes_string(x = dependent_response_ind), bins = 30) +
  facet_grid(. ~ Target) +
  labs(title = title_response_ind, x = x_label_ind, y = y_label_ind) +
  ggsave(filename = plot_name)

# Information about the N values in each condition
tableData <- ind_data %>%
  group_by(Target) %>%
  summarise(N = length(.data[[dependent_response_ind]]))

tableData %>%
  kable() %>%
  kable_styling()
```

The distribution for each condition is similar to the overall data distribution. This similarity tells me that most individuals finished with about 50 seconds or so left at the end of each session. 

*Reflection:* It seems as though we can say the high performing individuals finished with over 50 seconds or so left at the end of the session. Do high performing individuals have similar characteristics? How should we define a "high performing" individual? Overall, the distribution at the team level is similar to the distribution at the team level. 
  
  
#### Summary / Reflection

Overall, the data skewed to the left. According to the count at the individual and team level, there were fewer teams and fewer players that finished with more than 50 seconds or so left at the end of the session. We could say that the players and the teams that finished above this 50 seconds (or so) threshold were high performing / faster teams. A question that could be asked is do these "quick / high performing" teams have similar characteristics? 

There did not seem to be any obvious pattern when grouping the data by Feedback conditions. Maybe the feedback conditions influenced the amount of time remaining depending on their experience (i.e., session order)? 

### Q: Is there exciting variation among the *time remaining* that explains how the feedback conditions influence the time remaining when session order is taken into consideration?

#### Team

```{r}
dependent_response_team <- "timeRemaining_team"
y_label_team <- "Count"
x_label_team <- "Time Remaining"
title_response_team <- "Distribution of Time Remaining (Team)"
plot_name <- "Histogram_TimeRemaining_ByTarget_BySessionOrder_Team.png"
setwd(figure_directory)

plot_data_team <- team_data %>%
  select(dependent_response_team, Target, SessionOrder)

ggplot(data = plot_data_team) + 
  geom_histogram(aes_string(x = dependent_response_team), bins = 30) +
  labs(title = title_response_team, x = x_label_team, y = y_label_team) +
  facet_grid( SessionOrder ~ Target) + 
  ggsave(filename = plot_name)

# Information about the N values in each condition
tableData <- team_data %>%
  select(dependent_response_team, Target, SessionOrder) %>%
  group_by(Target, SessionOrder) %>%
  summarise(N = length(.data[[dependent_response_team]]))

tableData %>%
  kable() %>%
  kable_styling()
```

It looks like the distribution for time remaining for teams in the individual feedback condition did not change with more experience. The lack of change is unsual because I would expect the distrabution to move the right (i.e., increase with more experience). 
  
It looks like the distribution for time remaining for the Ind_Team condition seems to spread (or flatten) over time, which means that the teams were completing the task faster with more experience.
  
It looks like the distribution of the amount of time remaining at the end of the session in the team feedback condition starts to spread over time.

*Reflection:* I would expect to see the distribution of time remaining to move to the right over time because the teams would will have more experience with the task and get better at the task. This pattern is not followed in the individual condition. The distribution of the time remaining in the individual condition does not seem to improve over time. The amount of time remaining seems to be consistent no matter what session order (i.e., 2,3, or 4) they are in. This consistency would suggest that giving individual performance metrics does not influence the amount of time remaining at the end of the session for a team. 

The distribution for the Ind_Team and Team condition seem to spread (i.e., flatten) over time instead of moving from let to right. To me, this suggest that there are some time that get better with time in these conditions and there are other teams that do no get better with time. 

#### Individual

```{r}
dependent_response_ind <- "timeRemaining_ind"
y_label_ind <- "Count"
x_label_ind <- "Time Remaining"
title_response_ind <- "Distribution of Time Remaining (Individual)"
plot_name <- "Histogram_TimeRemaining_ByTarget_BySessionOrder_Ind.png"
setwd(figure_directory)

plot_data_ind <- ind_data %>%
  select(dependent_response_ind, Target, SessionOrder)

ggplot(data = plot_data_ind) + 
  geom_histogram(aes_string(x = dependent_response_ind), bins = 30) +
  facet_grid(SessionOrder ~ Target) +
  labs(title = title_response_ind, x = x_label_ind, y = y_label_ind) +
  ggsave(filename = plot_name)

# Information about the N values in each condition
tableData <- ind_data %>%
  select(dependent_response_ind, Target, SessionOrder) %>%
  group_by(Target, SessionOrder) %>%
  summarise(N = length(.data[[dependent_response_ind]]))

tableData %>%
  kable() %>%
  kable_styling()
```

It looks like the distribution of the time remaining in the individual condition does not spread over time. This lack of spread tells me that the individuals were not getting faster over time in the individual feedback condition. It looks like the spread of the time remaining in the Ind_Team condition does spread over time. There is a more obvious spread from session 3 to session 4. It looks like the time remaining in the team condition does spread over time.

*Reflection:* I am getting the sense that the individual condition did not influence how quickly the participants completed the session. In other words, giving the individual feedback on performance metrics did not encourage the participants to move faster through the session. However, it looks like the distrabution of the time remaining flattens when groups are given Team or Ind_Team feedback. This tells me that teams are more likely to move through the task quicker if given Ind_Team or Team feedback, not individual feedback. 


#### Summary / Reflection

Overall, the distribution is telling me that over time, teams move through the task quicker when given Team or Ind_Team feedback but not individual feedback. This suggests that if I looked at the fourth session and group the data by the feedback conditions, I would see that the time remaining in the Ind_Team and Team condition would be different from the time remaining in the individual condition.

### Q: Is there an *interaction* between the Target and Session Order for the *time remaining*?

I am interested in this question for modeling purposes. I want to know if I need to include the interaction between Target and Session Order. 

#### Team

```{r fig.width= 10}
dependent_response_team <- "timeRemaining_team"
y_label_team <- "Time Remaining"
x_label_team <- "Target"
title_response_team <- "Time Remaining (Team) Vs. Target"
value_threshold <- 120
plot_name <- "Bar_TimeRemaining_ByTarget_BySessionOrder_Team.png"
setwd(figure_directory)

plot_data_team <- team_data %>%
  select(Target, SessionOrder, dependent_response_team, Team) %>%
  mutate(rank_order = -rank(team_data[[dependent_response_team]])) %>%
  mutate(above_value_threshold = .data[[dependent_response_team]] > value_threshold)

names <- ifelse(plot_data_team[,"above_value_threshold"], as.character( plot_data_team[["Team"]]), "")

ggplot(data = plot_data_team, 
       aes(x = factor(SessionOrder), 
                  y = .data[[dependent_response_team]], 
                  fill = Team, group = rank_order,
                  label = names )) +
  geom_text(position = position_dodge(1), vjust = 0, aes(y = .data[[dependent_response_team]] + 15), check_overlap = FALSE) +
  geom_bar(stat = "identity", position = "dodge") + 
  facet_grid(. ~ Target) + 
  guides(fill = FALSE) +
  coord_flip()+
  xlim("4", "3", "2") +
  labs(y = y_label_team, x = x_label_team, title = title_response_team, fill = "Teams") +
  ggsave(filename = plot_name)

sumDataCount <- plot_data_team %>%
  group_by(Target, SessionOrder) %>%
  summarise(N = length(.data[[dependent_response_team]]))

sumDataCount %>%
  kable() %>%
  kable_styling()
```

Visually, the first thing that jumps out to me that there seem to be a few outliers that may be influencing the results. 

Let's call a group "fast" if that group has more than `r value_threshold` seconds left at the end of the session. The teams that are labeled had more than `r value_threshold` seconds (`r value_threshold / 60` minutes) remaining at the end of the session. This value is an arbitrary value.

The groups that are labeled in all the conditions (Target levels) are team 26, 45, 13. Some of these teams data may be outliers. 

*Reflection:* This figure tells me that I may need to consider removing these teams because they may be outliers. However, I do not have a good reason to remove the values. Instead, I considered teams, that seemed to be outliers, fast teams. These are the teams that had more than `r value_threshold` seconds (`r value_threshold / 60` minutes) remaining. If I want to look at the characterisitics of fast groups, I could use teams 13, 26, and 45 as fast moving teams. 


```{r}
dependent_response_team <- "timeRemaining_team"
y_label_team <- "Time Remaining"
x_label_team <- "Target"
title_response_team <- "Time Remaining (Team) Vs. Target"
plot_name <- "InteractionPlot_TimeRemaining_ByTarget_BySessionOrder_Team.png"
setwd(figure_directory)

plot_data_team <- team_data %>%
  select(Target, SessionOrder, timeRemaining_team) %>%
  group_by(SessionOrder, Target) %>%
  summarise(timeRemaining_teamAverage = mean(timeRemaining_team), 
            Stdv =sd(timeRemaining_team), n = length(timeRemaining_team), 
            StEr = sd(timeRemaining_team) / sqrt(length(timeRemaining_team)))

ggplot(data = plot_data_team, aes(x = Target, y = timeRemaining_teamAverage, color = SessionOrder, shape = SessionOrder)) +
  geom_point(size = 3) +
  geom_line(aes(group=SessionOrder, color = SessionOrder)) + 
  geom_errorbar(aes(ymin = timeRemaining_teamAverage - StEr, ymax = timeRemaining_teamAverage + StEr), width = 0.2) +
  labs(y = y_label_team, x = x_label_team, title = title_response_team, color = "Session", shape = "Session") +
  ggsave(filename = plot_name)

```

Visually, there appears to be some level of interaction between Target and SessionOrder for the time remaining. The interaction does not seem to be strong. The graph suggests that the average time remaining at the end of the session increases over time. The increase is particularly noticeable in the Ind_Team condition going from session 3 to session 4.  In other words, when given Ind_Team feedback, the amount of time remaining at the end of each session increases faster. 

*Reflection:* There seems to be some level of interaction but I am getting the sense that it is not a strong interaction. I'll have to run statistical tests to examine the strength of the effect to determine if there is an interaction effect. 

```{r}
dependent_response_team <- "timeRemaining_team"
y_label_team <- "Time Remaining"
x_label_team <- "Target"
title_response_team <- "Time Remaining (Team) Vs. Session Order"
plot_name <- "InteractionPlot_TimeRemaining_BySessionOrder_ByTarget_Team.png"
setwd(figure_directory)

plot_data_team <- team_data %>%
  select(Target, SessionOrder, timeRemaining_team) %>%
  group_by(SessionOrder, Target) %>%
  summarise(timeRemaining_teamAverage = mean(timeRemaining_team), 
            Stdv =sd(timeRemaining_team), n = length(timeRemaining_team), 
            StEr = sd(timeRemaining_team) / sqrt(length(timeRemaining_team)))

ggplot(data = plot_data_team, aes(x = SessionOrder , y = timeRemaining_teamAverage, color = Target, shape = Target)) +
  geom_point(size = 3) +
  geom_line(aes(group=Target, color = Target)) + 
  geom_errorbar(aes(ymin = timeRemaining_teamAverage - StEr, ymax = timeRemaining_teamAverage + StEr), width = 0.2) +
  labs(y = y_label_team, x = x_label_team, title = title_response_team, color = "Session", shape = "Session") +
  ggsave(filename = plot_name)
```

There appears to be an interaction between the Target and Session Order variable. This figure tells me that over time the amount of time remaining at the end of each session increases over time. This figure tells me that in the different session orders, the amount of time remaining is roughly the same in after 4 sessions. However, over time, the amount of time remaining at the end of the session changes differently depending on the feedback condition. 
  
The individual session steadily improves over time. 

The Individual_Team session has a small improvement from session 2 to session 3, but there is a substantial increase from session 3 to session 4. This tells me that for some reason there was little change between session 2 and session 3, but something happened that caused a major improvement from session 3 to session 4. 

The team session showed a substantial increase from session 2 to 3 but a small improvement from session 3 to session 4. This suggests that for some reason there was a major improvement between session 2 and session 3, but there was little gain between session 3 and session 4. This could mean that the feedback was no longer useful between 3 and 4 or that the teams reached their highest performance. 

*Reflection:* I am getting the session that the team condition encouraged teams to move quicker through the session. There was a substantial increase in the amount of time remaining at the end of the session in the Team condition when moving from session 2 to session 3. I am also getting the sense that the Ind_Team feedback condition may be encouraging a team to move quicker through the task as well. However, it looks like the effect of the Ind_Team feedback takes longer to take effect. Even so, the amount of time remaining at the end of the session ended up being about the same after four sessions in the Ind_Team and the Team condition.


#### Individual

```{r}
dependent_response_ind <- "timeRemaining_ind"
y_label_ind <- "Time Remaining"
x_label_ind <- "Target"
title_response_ind <- "Time Remaining (Individual) Vs. Target"
value_threshold <- 120
plot_name <- "Bar_TimeRemaining_ByTarget_BySessionOrder_Ind.png"
setwd(figure_directory)

plot_data_ind <- ind_data %>%
  select(Target, SessionOrder, dependent_response_ind, Player_ID) %>%
  mutate(rank_order = -rank(.data[[dependent_response_ind]])) %>%
  mutate(above_value_threshold = .data[[dependent_response_ind]] > value_threshold)

names <- ifelse(plot_data_ind[,"above_value_threshold"], as.character( plot_data_ind[["Player_ID"]]), "")

ggplot(data = plot_data_ind, 
       aes(x = factor(SessionOrder), 
                  y = .data[[dependent_response_ind]], 
                  fill = Player_ID, group = rank_order,
                  label = names )) +
  geom_bar(stat = "identity", position = "dodge") + 
  facet_grid(. ~ Target) + 
  guides(fill = FALSE) +
  coord_flip()+
  xlim("4", "3", "2") +
  labs(y = y_label_ind, x = x_label_ind, title = title_response_ind, fill = "Player_ID") +
  ggsave(filename = plot_name)

ggplot(data = plot_data_ind, 
       aes(x = factor(SessionOrder), 
           y = .data[[dependent_response_ind]], 
           fill = Player_ID, group = rank_order,
           label = names )) +
  geom_text_repel(stat = "identity", position = position_jitterdodge(), force = 5) +
  geom_point(position = position_jitterdodge()) +
  facet_grid(. ~ Target) + 
  guides(fill = FALSE) +
  coord_flip()+
  xlim("4", "3", "2") +
  labs(y = y_label_ind, x = x_label_ind, title = title_response_ind, fill = "Player ID") +
  ggsave(filename = "Point_TimeRemaining_ByTarget_BySessionOrder_Ind.png", width = 10)

sumDataCount <- plot_data_ind %>%
  group_by(Target, SessionOrder) %>%
  summarise(N = length(.data[[dependent_response_ind]]))

sumDataCount %>%
  kable() %>%
  kable_styling()

sumCountFastParticipants <- plot_data_ind %>%
  filter(above_value_threshold) %>%
  group_by(Target, SessionOrder) %>%
  summarise(N_fast = length(.data[[dependent_response_ind]])) 

sumCountFastParticipants %>%
  kable() %>%
  kable_styling()

```

Visually, it looks like some participants moved quickly through the task (i.e., possible outliers). It seems like there are more "fast" participants in session for in the Team condition. 

*Reflection:* It looks like pariticipants were moving slower in the Ind condition when compared to the Ind_Team and Team condition. I'm getting the sense that for some reason the individuals were moving fast in the Team condition. Or, participants were getting faster quicker in the Team condition.


```{r}
dependent_response_ind <- "timeRemaining_ind"
y_label_ind <- "Time Remaining"
x_label_ind <- "Target"
title_response_ind <- "Time Remaining (Individual) Vs. Target"
plot_name <- "InteractionPlot_TimeRemaining_ByTarget_BySessionOrder_Ind.png"
setwd(figure_directory)

plot_data_ind <- ind_data %>%
  select(Target, SessionOrder, dependent_response_ind) %>%
  group_by(SessionOrder, Target) %>%
  summarise(Average = mean(.data[[dependent_response_ind]]), 
            Stdv =sd(.data[[dependent_response_ind]]), 
            n = length(.data[[dependent_response_ind]]), 
            StEr = sd(.data[[dependent_response_ind]]) / sqrt(length(.data[[dependent_response_ind]])))

ggplot(data = plot_data_ind, aes(x = Target, y = Average, color = SessionOrder, shape=SessionOrder)) +
  geom_point(size = 3) +
  geom_line(aes(group=SessionOrder, color = SessionOrder)) + 
  geom_errorbar(aes(ymin = Average - StEr, ymax = Average + StEr), width = 0.2) +
  labs(y = y_label_ind, x = x_label_ind, title = title_response_ind, fill = "Players") + 
  ggsave(filename = plot_name)

```

There appears to be an interaction between Target and Session Order. Overall, the amount of time at the end of the session increases over time. It looks like there is a considerable increase in the amount of time remaining in the Team condition from Session 2 to session 3. This substantial increase suggests that giving team feedback resulted in individuals moving faster. It looks like something is happening in the Team and Ind_Team condition. In the Ind condition, there is a steady increase in the amount of time remaining. In the Ind_Team condition, there was little to no change in the time remaining between session 2 and 3 but a big change from session 3 to 4. 

*Reflection:* I am getting the sense that something is happening with the Ind_Team and the Team condition. For some reason, there are these large increases in the time remaining. 

```{r}
dependent_response_ind <- "timeRemaining_ind"
y_label_ind <- "Time Remaining"
x_label_ind <- "Target"
title_response_ind <- "Time Remaining (Individual) Vs. Target"
plot_name <- "InteractionPlot_TimeRemaining_BySessionOrder_ByTarget_Ind.png"
setwd(figure_directory)

plot_data_ind <- ind_data %>%
  select(Target, SessionOrder, dependent_response_ind) %>%
  group_by(SessionOrder, Target) %>%
  summarise(Average = mean(.data[[dependent_response_ind]]), 
            Stdv =sd(.data[[dependent_response_ind]]), 
            n = length(.data[[dependent_response_ind]]), 
            StEr = sd(.data[[dependent_response_ind]]) / sqrt(length(.data[[dependent_response_ind]])))

ggplot(data = plot_data_ind, aes(x = SessionOrder, y = Average, color = Target, shape=Target)) +
  geom_point(size = 3) +
  geom_line(aes(group=Target, color = Target)) + 
  geom_errorbar(aes(ymin = Average - StEr, ymax = Average + StEr), width = 0.2) +
  labs(y = y_label_ind, x = x_label_ind, title = title_response_ind, fill = "Players") +
  ggsave(filename = plot_name)
```

There seems to be an interaction between the session order and the target variable. 

In the Ind condition, there is a steadying increase in the time remaining at the individual level. 

In the Team condition, there is a large improvement from session 2 to session 3 but little to no improvement from session 3 to session 4. 

In the Ind_Team condition, there is little to no improvement from session 2 to session 3 but a large improvement from session 3 to session 4. 

*Reflection:* I get the sense that something interesting is going on with the Ind_Team and Team conditions. The figure suggests that both sessions have a positive influence (i.e., increase the amount of time remaining) on how fast participants move through the session. It seems as though the positive effect of the Team condition happens quicker than the impact of the Ind_Team condition.

#### Summary / Reflection

I am getting the sense that there is something interesting happening with the Ind_Team condition and Team condition. For some reason, the positive effect (i.e., the large increase in the time remaining at the end of the session) in the Team condition happens quicker than the positive effect from the Ind_Team condition. More exploration is needed to understand why this apparent effect is happening. Some statistical analysis is necessary to determine the strength of this effect if it exists. Also, statistical tests are needed to determine if there is an interaction between the Target and SessionOrder variable for the individual and team level.


### Q: Is there an interaction between the Target and Session Order for the *time remaining* that is statistically significant?

I am interested in determining if a linear mixed effect model should include the interaction effect between the Target and Session Order variable.

There are a few steps I will take. First, I will fit the multiple models using the data provided. Second, I will compare those models to the null model. Third, I will pick the models that are worth exploring further (e.g., models that are significantly different from the null model). Fourth, I will evaluate the effect size ($R^2$) of the fixed effect and random effect variables using a method by [@Nakagawa2013, @Johnson2014]. Lastly, I will analyze the assumptions for the residuals. 

A note on the effect size ($R^2$). This method generates two types of ($R^2$) values called marginal ($R_{m}^2$) and conditional ($R_{c}^2$) effect size. The $R_{m}^2$ calculates how much of the variance is described by the fixed effect variables (feedback condition and session order) while the $R_{c}^2$ calculates how much of the variance is described by both the fixed and random effect variables.

#### Full Models Used for Team and Individual

The next two sections below describe the full model for team and individual level analysis. Five models were fitted and then compared. One model was the null model, one model was the full model, and the last three are a subset of the full model.

##### Team Full Model

$$ y_{ijt} = \mu + \alpha_{i} + \beta_{j} + \alpha_{i} \beta_{j} + \gamma_{t} +   \epsilon_{ijt}$$ 

Where $y_{ijt}$ is the response variable (e.g., team score), $\mu$ is the baseline (or intercept), $\alpha_{i}$ is the fixed effect for the $i^(th)$ feedback target category, $\beta_{j}$ is the fixed effect for the $j^(th)$ session order, $\gamma_{t}$ is the random effect for the $t^(th)$ team, $ \alpha_{i} \beta_{j}$ is the fixed effect of the interaction between Target and Session Order, and $\epsilon_{ijt}$ is the residual for the model. 

##### Individual Team Full Model

$$ y_{ijtp} = \mu + \alpha_{i} + \beta_{j} + \alpha_{i} \beta_{j} + \gamma_{t} + \theta_{p} + \epsilon_{ijtp}$$ 

Where $y_{ijtp}$ is the response variable (e.g., individual score), $\mu$ is the baseline (or intercept), $\alpha_{i}$ is the fixed effect for the $i^(th)$ feedback target category, $\beta_{j}$ is the fixed effect for the $j^(th)$ session order, $\gamma_{t}$ is the random effect for the $t^(th)$ team, $\theta_{p}$ is the random effect for the $p^(th)$ individual, $ \alpha_{i} \beta_{j}$ is the fixed effect of the interaction between Target and Session Order, and $\epsilon_{ijtp}$ is the residual for the model.


#### Team

```{r message=FALSE}
# Data to fit
data_modified_team <- team_data %>%
  select(TeamScore,
         timeRemaining_team,
         Target, 
         SessionOrder, 
         Team)

# Generate models with variable response
response_variable <- "timeRemaining_team"
data_focus_team <- data_modified_team
model.null <- model_data_Target_Session(df = data_focus_team, dependent =  response_variable, model.type =  "null", is.team = TRUE, is.robust =FALSE)
model.All <- model_data_Target_Session(df = data_focus_team, dependent =  response_variable, model.type =  "All", is.team = TRUE, is.robust = FALSE)
model.NoInteraction <- model_data_Target_Session(df = data_focus_team, dependent =  response_variable, model.type =  "NoInteraction", is.team = TRUE, is.robust = FALSE)
model.NoInteraction.NoTarget <- model_data_Target_Session(df = data_focus_team, dependent =  response_variable, model.type =  "NoInteraction_NoTarget", is.team = TRUE, is.robust = FALSE)
model.NoInteraction.NoSession <- model_data_Target_Session(df = data_focus_team, dependent =  response_variable, model.type =  "NoInteraction_NoSession", is.team = TRUE, is.robust = FALSE)

# There is an option to compare all the models with the anova(). However, the function does not compare all models to model.null
anova(model.null,
      model.All) %>%
  kable(caption = "ANOVA: Null and All") %>%
  kable_styling()

anova(model.null,
      model.NoInteraction) %>%
  kable(caption = "ANOVA: Null and No.Interaction") %>%
  kable_styling()

anova(model.null,
      model.NoInteraction.NoTarget) %>%
  kable(caption = "ANOVA: Null and No.Interaction.No.Target") %>%
  kable_styling()

anova(model.null,
      model.NoInteraction.NoSession) %>%
  kable(caption = "ANOVA: Null and No.Interaction.No.Session") %>%
  kable_styling()

```

The following models were significantly different from the null model: model.All,  model.NoInteraction, model.NoInteraction.NoTarget. 

model.All: Session Order, Target, and the interaction are included in this model.

model.NoInteraction: Session order and target are the fixed effects in this model.

model.NoInteraction.NoTarget: Session order is the only fixed effect in this model.


```{r}
anova(model.All,
      model.NoInteraction) %>%
  kable(caption = "ANOVA: All and No.Interaction") %>%
  kable_styling()

anova(model.All,
      model.NoInteraction.NoTarget) %>%
  kable(caption = "ANOVA: All and NoInteraction.NoTarget") %>%
  kable_styling()

anova(model.NoInteraction,
      model.NoInteraction.NoTarget) %>%
  kable(caption = "ANOVA: No.Interaction and NoInteraction.NoTarget") %>%
  kable_styling()
```

The results show that the model with the interaction (i.e., Model.All) was not significantly better at describing the data than the other two models (i.e.,model.NoInteraction.NoTarget and model.NoInteraction). According to this result, we can confidently remove the interaction effect from the model.

The results also show that the model.NoInteraction is not significantly different from model.NoInteraction.NoTarget. This lack of significance suggests that the model.NoInteraction.NoTarget describes the data best. I notice there is a small difference in the AIC (`r anova(model.NoInteraction, model.NoInteraction.NoTarget)["model.NoInteraction","AIC"] - anova(model.NoInteraction, model.NoInteraction.NoTarget)["model.NoInteraction.NoTarget","AIC"]`) and the BIC (`r anova(model.NoInteraction, model.NoInteraction.NoTarget)["model.NoInteraction","BIC"] - anova(model.NoInteraction, model.NoInteraction.NoTarget)["model.NoInteraction.NoTarget","BIC"]`) criteria values. I am not comfitent 

I want to calculate the effect size of both models to see if there is a noticeable difference between the effect sizes.


```{r}
# Effect size (R^2)

r.squaredGLMM(model.NoInteraction.NoTarget) %>%
  kable(caption = "Table: Effect size for *No Interaction and No Target*") %>%
   kable_styling(full_width = F)

r.squaredGLMM(model.NoInteraction) %>%
  kable(caption = "Table: Effect size for *No Interaction*") %>%
   kable_styling(full_width = F)
```

There is little difference between the effect sizes for both models. The results show that model.NoInteraction has a slightly better effect size. However, the difference is not noticeably different. 


*Reflection:* The models that are significantly different from the null model are model.All, model.NoInteraction, model.NoInteraction.NoTarget. Comparing these three models showed that the model.All was not significantly better than model.NoInteraction or model.NoInteraction.NoTarget. Comparing model.NoInteraction and model.NoInteraction.NoTarget showed no significant difference between the models (i.e., model.NoInteraction did not explain the data better than model.NoInteraction.NoTarget), suggesting that adding the Target variable did not significantly improve the model. However, I noted that the AIC and BIC values were similar. The effect size for both models was examined to determine if one model had a noticeably higher effect size than the other model. There was no noticeable difference in effect size, but the results indicated that model.NoInteraction had a slightly higher effect size. Model.NoInteraction is the model that I am interested in but I cannot I cannot confidently ignore the model of least interest (i.e., model.NoInteraction.NoTarget). Therefore, I will include model.NoInteraction.NoTarget in further analysis.



#### Individual

```{r, message=FALSE}
# Data to model
data_modified_ind <- ind_data %>%
  select(timeRemaining_ind,
         Target, 
         SessionOrder, 
         Team, 
         Player_ID)

response_variable <- "timeRemaining_ind"
data_focus_ind <- data_modified_ind
model.null <- model_data_Target_Session(df = data_focus_ind, dependent =  response_variable, model.type =  "null", is.team = FALSE, is.robust = FALSE)
model.All <- model_data_Target_Session(df = data_focus_ind, dependent =  response_variable, model.type =  "All", is.team = FALSE, is.robust = FALSE)
model.NoInteraction <- model_data_Target_Session(df = data_focus_ind, dependent =  response_variable, model.type =  "NoInteraction", is.team = FALSE, is.robust = FALSE)
model.NoInteraction.NoTarget <- model_data_Target_Session(df = data_focus_ind, dependent =  response_variable, model.type =  "NoInteraction_NoTarget", is.team = FALSE, is.robust = FALSE)
model.NoInteraction.NoSession <- model_data_Target_Session(df = data_focus_ind, dependent =  response_variable, model.type =  "NoInteraction_NoSession", is.team = FALSE, is.robust = FALSE)

# There is an option to compare all the models with the anova(). However, the function does not compare all models to model.null
anova(model.null,
      model.All) %>%
  kable(caption = "ANOVA: Null and All") %>%
  kable_styling()

anova(model.null,
      model.NoInteraction) %>%
  kable(caption = "ANOVA: Null and No.Interaction") %>%
  kable_styling()

anova(model.null,
      model.NoInteraction.NoTarget) %>%
  kable(caption = "ANOVA: Null and No.Interaction.No.Target") %>%
  kable_styling()

anova(model.null,
      model.NoInteraction.NoSession) %>%
  kable(caption = "ANOVA: Null and No.Interaction.No.Session") %>%
  kable_styling()

```

All of the models were significantly different from the null model (i.e., model.All, model.NoInteraction, model.NoInteraction.NoTarget, and model.NoInteraction.NoSession).

model.All: Session Order, Target, and the interaction are included in this model.

model.NoInteraction: Session order and target are the fixed effects in this model.

model.NoInteraction.NoTarget: Session order is the only fixed effect in this model.

model.NoInteraction.NoSession: Target is the only fixed effect in this model. 

```{r}
anova(model.All,
      model.NoInteraction) %>%
  kable(caption = "ANOVA: All and No.Interaction") %>%
  kable_styling()

anova(model.All,
      model.NoInteraction.NoTarget) %>%
  kable(caption = "ANOVA: All and NoInteraction.NoTarget") %>%
  kable_styling()

anova(model.All,
      model.NoInteraction.NoSession) %>%
  kable(caption = "ANOVA: All and NoInteraction.NoSession") %>%
  kable_styling()

anova(model.NoInteraction,
      model.NoInteraction.NoTarget) %>%
  kable(caption = "ANOVA: No.Interaction and NoInteraction.NoTarget") %>%
  kable_styling()

anova(model.NoInteraction,
      model.NoInteraction.NoSession) %>%
  kable(caption = "ANOVA: No.Interaction and NoInteraction.NoSession") %>%
  kable_styling()

anova(model.NoInteraction.NoTarget,
      model.NoInteraction.NoSession) %>%
  kable(caption = "ANOVA: NoInteraction.NoTarget and NoInteraction.NoSession") %>%
  kable_styling()
```

The results show that model.NoInteraction is significantly different from model.NoInteraction.NoTarget and NoInteraction.NoSession. The significant difference means that the model should include the effect of Target and Session Order. The results show that model.All is not significantly from model.NoInteraction. This result tells me that I can confidently remove the interaction effect from the model. I will now calculate the effect size of model.All and model.NoInteraction to examine if there is a noticeable difference between the effect sizes.


```{r}
# Effect size (R^2)

r.squaredGLMM(model.NoInteraction) %>%
  kable(caption = "Table: Effect size for *No Interaction*") %>%
   kable_styling(full_width = F)

r.squaredGLMM(model.All) %>%
  kable(caption = "Table: Effect size for *All*") %>%
   kable_styling(full_width = F)
```


*Reflection:* Ultimately, the data suggests that the model.NoInteraction is the best model to use. It is significantly different from the mode.Null but model.All (i.e., including the interaction effect) does significantly improve the model.


#### Summary / Reflection

At the team level, the models that seem to fit the data best is __model.NoInteraction.NoTarget__ and __model.NoInteraction__. The answer to the original question (is the interaction significant) is that the results suggest the model should not include the interaction effect.

At the individual level, the model that seems to fit the data best is __model.NoInteraction__. The answer to the original question is that the results suggest the model should not include the interaction effect.

My next step is to examine the models and see what I can learn from these models. Are any of the effects in these models significantly different from zero?


### Q: Are any of the effects in the models statistically different from zero?

The purpose of this question is to see what we can learn from these models. Before I examine the model by generating diagnostic plots for the models. The assumptions are as follows [@Galwey2014]:

1. The residuals should have an approximately normal distribution (i.e., a bell curve) when plotted on a histogram.
2. A fitted-value plot should show an almost constant width when viewed from left to right.
3. The points on a normal plot should lie on an almost straight line from the bottom left to the top right.

The models may violate some of the assumptions. According to @Field2017, the best way to examine the influence of assumption violations is to compare a robust model to a standard model. When models violate assumptions, I will compare a robust model to a classic model. If there is a noticeable difference between the two models (i.e., if the estimated coefficient are noticeably different) then I will use a step on the power ladder to transform (@Tukey1977), or re-express, the data to address the assumption violation.

#### Team

We learned that __model.NoInteraction.NoTarget__ and __model.NoInteraction__ best describe the team level data at the team level (see previous analysis)

```{r}
# Data to fit
data_modified_team <- team_data %>%
  select(TeamScore,
         timeRemaining_team,
         Target, 
         SessionOrder, 
         Team)

# Generate models with variable response
response_variable <- "timeRemaining_team"
data_focus_team <- data_modified_team
model.NoInteraction <- model_data_Target_Session(df = data_focus_team, dependent =  response_variable, model.type =  "NoInteraction", is.team = TRUE, is.robust = FALSE)

# Histogram of Residuals - model.NoInteraction
ggplot(model.NoInteraction, aes(x = .resid)) +
  geom_histogram(bins = 30) + 
  labs(title = paste("Histogram of Residuals for model.NoInteraction"), x = "", y = "") +
  theme(plot.title = element_text(hjust = 0.5))

# Fitted values - model.NoInteraction
ggplot(model.NoInteraction, aes(x = .fitted, y = .resid)) +
  geom_point() + 
  geom_hline(yintercept = 0)+
  labs(title = paste("Fitted-Value Plot for model.NoInteraction"), x = "Fitted Values", y = "Residuals") +
  theme(plot.title = element_text(hjust = 0.5)) 

# QQ plots - model.NoInteraction
ggplot(model.NoInteraction, aes(sample = .resid)) +
  stat_qq() +
  stat_qq_line()+
  labs(title = "Normal Q-Q Plot for NoInteraction", x = "Theoretical", y = "Sample") +
   theme(plot.title = element_text(hjust = 0.5))
```

model.NoInteraction: Visually, it looks like the model violates assumption 2 and 3 in the fitted-value plot and the QQ plot, respectively. I will need to compare this model to a robust model to examine the influence of the apparent violation. If there is a noticeable difference, I will need to transform the data.


```{r}
# Data to fit
data_modified_team <- team_data %>%
  select(TeamScore,
         timeRemaining_team,
         Target, 
         SessionOrder, 
         Team)

# Generate models with variable response
response_variable <- "timeRemaining_team"
data_focus_team <- data_modified_team
model.NoInteraction.NoTarget <- model_data_Target_Session(df = data_focus_team, dependent =  response_variable, model.type =  "NoInteraction_NoTarget", is.team = TRUE, is.robust = FALSE)

# Histogram of Residuals - model.NoInteraction.NoTarget
ggplot(model.NoInteraction.NoTarget, aes(x = .resid)) +
  geom_histogram(bins = 30) + 
  labs(title = paste("Histogram of Residuals for model.NoInteraction.NoTarget"), x = "", y = "") +
  theme(plot.title = element_text(hjust = 0.5))


# Fitted values - model.NoInteraction.NoTarget
ggplot(model.NoInteraction.NoTarget, aes(x = .fitted, y = .resid)) +
  geom_point() + 
  geom_hline(yintercept = 0)+
  labs(title = paste("Fitted-Value Plot for model.NoInteraction.NoTarget"), x = "Fitted Values", y = "Residuals") +
  theme(plot.title = element_text(hjust = 0.5))

# QQ plots - model.NoInteraction.NoTarget
ggplot(model.NoInteraction.NoTarget, aes(sample = .resid)) +
  stat_qq() +
  stat_qq_line()+
  labs(title = "Normal Q-Q Plot for NoInteraction.NoTarget", x = "Theoretical", y = "Sample") +
   theme(plot.title = element_text(hjust = 0.5)) 
```

model.NoInteraction.NoTarget: Visually, it looks like the model violates assumption 2 and 3 in the fitted-value plot and the QQ plot, respectively. I will need to compare this model to a robust model to examine the influence of the apparent violation. If there is a noticeable difference, I will need to transform the data.

*Reflection:* It looks both models violated assumptions 2 and 3. In other words,  there may be a constant error violation (i.e., the fitted value plot is not consistent from left to right) and the QQ plot shows an assumption violation. I need to determine if this violation influences the model overall.


##### Q: Does the violation influence the linear model estimation?

I will use the robust estimation for linear mixed models found in the robustlmm package by @Koller2016. I will then compare the robust model to the non-robust model. If the estimated values are noticeably different, then data will need to be transformed. 


```{r}
# Data to fit
data_modified_team <- team_data %>%
  select(TeamScore,
         timeRemaining_team,
         Target, 
         SessionOrder, 
         Team)

response_variable <- "timeRemaining_team"
data_focus_team <- data_modified_team

# Generate robust and non-robust models - NoInteraction
model.NoInteraction <- model_data_Target_Session(df = data_focus_team, dependent =  response_variable, model.type =  "NoInteraction", is.team = TRUE, is.robust = FALSE)
rmodel.NoInteraction <- model_data_Target_Session(df = data_focus_team, dependent =  response_variable, model.type =  "NoInteraction", is.team = TRUE, is.robust = TRUE)

comparision_results <- compare(model.NoInteraction, rmodel.NoInteraction, show.rho.functions = FALSE)

comparision_results %>%
  kable(caption = "model.NoInteraction") %>%
  kable_styling()

```

The robust model.NoInteraction model is noticeably different from the non-robust model.NoInteraction. This suggests that the data should be transformed to satisfy the residual assumptions.

```{r}
# Data to fit
data_modified_team <- team_data %>%
  select(TeamScore,
         timeRemaining_team,
         Target, 
         SessionOrder, 
         Team)

response_variable <- "timeRemaining_team"
data_focus_team <- data_modified_team

# Generate robust and non-robust models - NoInteraction.NoTarget
model.NoInteraction.NoTarget <- model_data_Target_Session(df = data_focus_team, dependent =  response_variable, model.type =  "NoInteraction_NoTarget", is.team = TRUE, is.robust = FALSE)
rmodel.NoInteraction.NoTarget <- model_data_Target_Session(df = data_focus_team, dependent =  response_variable, model.type =  "NoInteraction_NoTarget", is.team = TRUE, is.robust = TRUE)

comparision_results <- compare(model.NoInteraction.NoTarget, rmodel.NoInteraction.NoTarget, show.rho.functions = FALSE)

comparision_results %>%
  kable(caption = "model.NoInteraction.NoTarget") %>%
  kable_styling()
```

The robust model.NoInteraction.NoTarget model is noticeably different from the non-robust model.NoInteraction.NoTarget This suggests that the data should be transformed to satisfy the residual assumptions.

*Reflection:* Comparing the normal estimation to the robust models indicates that the data should be transformed because the estimates are noticeably different.

##### Q: Does data transformation satisfy the assumptions of the residuals?

I will use the square root transformation method from Tukey's ladder [@Tukey1977]. 

```{r}
# Data to fit
data_modified_team <- team_data %>%
  select(TeamScore,
         timeRemaining_team,
         Target, 
         SessionOrder, 
         Team) %>%
  mutate(sqrt.value = sqrt(.data[["timeRemaining_team"]]))

response_variable <- "sqrt.value"
data_focus_team <- data_modified_team

# Generate non-robust models - NoInteraction
model.NoInteraction <- model_data_Target_Session(df = data_focus_team, dependent =  response_variable, model.type =  "NoInteraction", is.team = TRUE, is.robust = FALSE)

# Histogram of Residuals - model.NoInteraction
ggplot(model.NoInteraction, aes(x = .resid)) +
  geom_histogram(bins = 30) + 
  labs(title = paste("Histogram of Residuals for model.NoInteraction"), x = "", y = "") +
  theme(plot.title = element_text(hjust = 0.5))

# Fitted values - model.NoInteraction
ggplot(model.NoInteraction, aes(x = .fitted, y = .resid)) +
  geom_point() + 
  geom_hline(yintercept = 0)+
  labs(title = paste("Fitted-Value Plot for model.NoInteraction"), x = "Fitted Values", y = "Residuals") +
  theme(plot.title = element_text(hjust = 0.5)) 

# QQ plots - model.NoInteraction
ggplot(model.NoInteraction, aes(sample = .resid)) +
  stat_qq() +
  stat_qq_line()+
  labs(title = "Normal Q-Q Plot for model.NoInteraction", x = "Theoretical", y = "Sample") +
   theme(plot.title = element_text(hjust = 0.5))
```

The diagnostic plots suggest the transformation has resolved the assumption violations for the model.NoInteraction.

```{r}
# Data to fit
data_modified_team <- team_data %>%
  select(TeamScore,
         timeRemaining_team,
         Target, 
         SessionOrder, 
         Team) %>%
  mutate(sqrt.value = sqrt(.data[["timeRemaining_team"]]))

response_variable <- "sqrt.value"
data_focus_team <- data_modified_team

model.NoInteraction.NoTarget <- model_data_Target_Session(df = data_focus_team, dependent =  response_variable, model.type =  "NoInteraction_NoTarget", is.team = TRUE, is.robust = FALSE)

# Histogram of Residuals - model.NoInteraction.NoTarget
ggplot(model.NoInteraction.NoTarget, aes(x = .resid)) +
  geom_histogram(bins = 30) + 
  labs(title = paste("Histogram of Residuals for model.NoInteraction.NoTarget"), x = "", y = "") +
  theme(plot.title = element_text(hjust = 0.5))


# Fitted values - model.NoInteraction.NoTarget
ggplot(model.NoInteraction.NoTarget, aes(x = .fitted, y = .resid)) +
  geom_point() + 
  geom_hline(yintercept = 0)+
  labs(title = paste("Fitted-Value Plot for model.NoInteraction.NoTarget"), x = "Fitted Values", y = "Residuals") +
  theme(plot.title = element_text(hjust = 0.5))

# QQ plots - model.NoInteraction.NoTarget
ggplot(model.NoInteraction.NoTarget, aes(sample = .resid)) +
  stat_qq() +
  stat_qq_line()+
  labs(title = "Normal Q-Q Plot for NoInteraction.NoTarget", x = "Theoretical", y = "Sample") +
   theme(plot.title = element_text(hjust = 0.5)) 
```

The diagnostic plots suggest the transformation has resolved the assumption violations for the model.NoInteraction.NoTarget.

*Reflection:* The plots suggest that the data transformation resolved the residual assumption violations for both models. I will use a step on Tukey's ladder to transform the data.

##### Q: Are there any effects that are significant?

I want to determine if Target has a significant effect. I will examine the model itself, and then I will calculate the estimated marginal means to compare all three levels.

```{r}
# Data to fit
data_modified_team <- team_data %>%
  select(TeamScore,
         timeRemaining_team,
         Target, 
         SessionOrder, 
         Team) %>%
  mutate(sqrt.value = sqrt(.data[["timeRemaining_team"]]))

response_variable <- "sqrt.value"
data_focus_team <- data_modified_team

# Generate robust and non-robust models - NoInteraction
model.NoInteraction <- model_data_Target_Session(df = data_focus_team, dependent =  response_variable, model.type =  "NoInteraction", is.team = TRUE, is.robust = FALSE)

summary(model.NoInteraction)
```

The estimations are in reference to the Ind level for the Target variable and session 2 for the session order variable. The results suggest that session 3 and 4 have a significant effect. I expected this effect. The results also indicate that the impact of the Team and Ind_Team levels do not have an effect that is greater than zero, in reference to the Ind level.

```{r}
# Data to fit
data_modified_team <- team_data %>%
  select(TeamScore,
         timeRemaining_team,
         Target, 
         SessionOrder, 
         Team) %>%
  mutate(sqrt.value = sqrt(.data[["timeRemaining_team"]]))

response_variable <- "sqrt.value"
data_focus_team <- data_modified_team

# Generate robust and non-robust models - NoInteraction
model.NoInteraction <- model_data_Target_Session(df = data_focus_team, dependent =  response_variable, model.type =  "NoInteraction", is.team = TRUE, is.robust = FALSE)

emmeans(model.NoInteraction, list(pairwise ~ Target), adjust = "tukey")
```
The estimated marginal means show no significant difference among the Target variable. It does look like the different between Ind_Team and Team is approaching significance (p = .168). This approaching significance suggests that more data is needed.

```{r}
# Data to fit
data_modified_team <- team_data %>%
  select(TeamScore,
         timeRemaining_team,
         Target, 
         SessionOrder, 
         Team) %>%
  mutate(sqrt.value = sqrt(.data[["timeRemaining_team"]]))

response_variable <- "sqrt.value"
data_focus_team <- data_modified_team

# Generate robust and non-robust models - NoInteraction
model.NoInteraction <- model_data_Target_Session(df = data_focus_team, dependent =  response_variable, model.type =  "NoInteraction", is.team = TRUE, is.robust = FALSE)

emmeans(model.NoInteraction, list(pairwise ~ SessionOrder), adjust = "tukey")
```

The estimated marginal means show a significant difference between all of the sessions. This significance suggests that the amount of time remaining at the end of the session increased over time. In other words, the teams were getting faster over time.

*Reflection:* The *model.NoInteraction:* model shows no significant effect from the Target levels, but it does show a significant effect from the session order. Specifically, all of the session orders were significantly different from one another. The significance among the session orders means that the amount of time remaining at the end of each session increased over time. 

```{r}
# Data to fit
data_modified_team <- team_data %>%
  select(TeamScore,
         timeRemaining_team,
         Target, 
         SessionOrder, 
         Team) %>%
  mutate(sqrt.value = sqrt(.data[["timeRemaining_team"]]))

response_variable <- "sqrt.value"
data_focus_team <- data_modified_team

# Generate robust and non-robust models - NoInteraction_NoTarget
model.NoInteraction.NoTarget <- model_data_Target_Session(df = data_focus_team, dependent =  response_variable, model.type =  "NoInteraction_NoTarget", is.team = TRUE, is.robust = FALSE)

summary(model.NoInteraction.NoTarget)
```

The results show that that session 3 and 4 are significantly different from session 2.

```{r}
# Data to fit
data_modified_team <- team_data %>%
  select(TeamScore,
         timeRemaining_team,
         Target, 
         SessionOrder, 
         Team) %>%
  mutate(sqrt.value = sqrt(.data[["timeRemaining_team"]]))

response_variable <- "sqrt.value"
data_focus_team <- data_modified_team

# Generate robust and non-robust models - NoInteraction_NoTarget
model.NoInteraction.NoTarget <- model_data_Target_Session(df = data_focus_team, dependent =  response_variable, model.type =  "NoInteraction_NoTarget", is.team = TRUE, is.robust = FALSE)

emmeans(model.NoInteraction.NoTarget, list(pairwise ~ SessionOrder), adjust = "tukey")
```

The results show a significant difference between each session. 

*Refecltion:* As expected, the results show a significant difference among the session order. In other words, the amount of time remaining at the end of each session increased over time. 

##### Summary / Reflection

I had to transform the data to resolve assumption issues. I used one of the steps in the Tukey ladder @Tukey1977. I took the square root of all the values in the time remaining value for the teams.

Overall, the results show no significant effect from the Target variable, but it does show that the session order has a significant impact. This impact means that the amount of time remaining at the end of each session increased over time. I expected the effects of Session Order. There are no statistically significant results that I can discuss about Target.

#### Individual

We learned that __model.NoInteraction__ best describe the individual level data(see previous analysis).

```{r}
# Data to model
data_modified_ind <- ind_data %>%
  select(timeRemaining_ind,
         Target, 
         SessionOrder, 
         Team, 
         Player_ID)

# Generate models with variable response
response_variable <- "timeRemaining_ind"
data_focus_ind <- data_modified_ind
model.NoInteraction <- model_data_Target_Session(df = data_focus_ind, dependent =  response_variable, model.type =  "NoInteraction", is.team = FALSE, is.robust = FALSE)

# Histogram of Residuals - model.NoInteraction
ggplot(model.NoInteraction, aes(x = .resid)) +
  geom_histogram(bins = 30) + 
  labs(title = paste("Histogram of Residuals for model.NoInteraction"), x = "", y = "") +
  theme(plot.title = element_text(hjust = 0.5))

# Fitted values - model.NoInteraction
ggplot(model.NoInteraction, aes(x = .fitted, y = .resid)) +
  geom_point() + 
  geom_hline(yintercept = 0)+
  labs(title = paste("Fitted-Value Plot for model.NoInteraction"), x = "Fitted Values", y = "Residuals") +
  theme(plot.title = element_text(hjust = 0.5)) 

# QQ plots - model.NoInteraction
ggplot(model.NoInteraction, aes(sample = .resid)) +
  stat_qq() +
  stat_qq_line()+
  labs(title = "Normal Q-Q Plot for NoInteraction", x = "Theoretical", y = "Sample") +
   theme(plot.title = element_text(hjust = 0.5)) 
```

model.NoInteraction: Visually, it looks like the model violates assumption 2 and 3 in the fitted-value plot and the QQ plot, respectively. I will need to compare this model to a robust model to examine the influence of the apparent violation. If there is a noticeable difference, I will need to transform the data.

*Reflection:* Overall, it looks like I need to compare the model to the robust models to see if the violation has any influence on the model estimation.

##### Q: Does the violation influence the model estimation?

I will use the robust estimation for linear mixed models found in the robustlmm package by @Koller2016. I will then compare the robust model to the non-robust model. If the estimated values are noticeably different, then data will need to be transformed. 

```{r}
# Data to model
data_modified_ind <- ind_data %>%
  select(timeRemaining_ind,
         Target, 
         SessionOrder, 
         Team, 
         Player_ID)

# Generate models with variable response
response_variable <- "timeRemaining_ind"
data_focus_ind <- data_modified_ind
model.NoInteraction <- model_data_Target_Session(df = data_focus_ind, dependent =  response_variable, model.type =  "NoInteraction", is.team = FALSE, is.robust = FALSE)
rmodel.NoInteraction <- model_data_Target_Session(df = data_focus_ind, dependent =  response_variable, model.type =  "NoInteraction", is.team = FALSE, is.robust = TRUE)

comparision_results <- compare(model.NoInteraction, rmodel.NoInteraction, show.rho.functions = FALSE)

comparision_results %>%
  kable(caption = "model.NoInteraction") %>%
  kable_styling()
```

There is a noticeable difference between the non-robust model and the robust model. This noticeable difference indicates that the data should be transformed to attempt to satisfy the assumptions.

*Reflection:* I need to transform the data because there is a very noticeable difference between the robust model and the non-robust model.

##### Q: Does data transformation satisfy the assumptions of the residuals?

I will use the square root transformation method from Tukey's ladder [@Tukey1977]. 

```{r}
# Data to model
data_modified_ind <- ind_data %>%
  select(timeRemaining_ind,
         Target, 
         SessionOrder, 
         Team, 
         Player_ID) %>%
  mutate(sqrt.value = sqrt(ifelse(.data[["timeRemaining_ind"]] < 0, 0, .data[["timeRemaining_ind"]]))) # Some fo the time remaining vaules are negative when the should be zero. I want to make sure those values are zero

response_variable <- "sqrt.value"
data_focus_ind <- data_modified_ind

# Generate models with variable response
model.NoInteraction <- model_data_Target_Session(df = data_focus_ind, dependent =  response_variable, model.type =  "NoInteraction", is.team = FALSE, is.robust = FALSE)

# Histogram of Residuals - model.NoInteraction
ggplot(model.NoInteraction, aes(x = .resid)) +
  geom_histogram(bins = 30) + 
  labs(title = paste("Histogram of Residuals for model.NoInteraction"), x = "", y = "") +
  theme(plot.title = element_text(hjust = 0.5))

# Fitted values - model.NoInteraction
ggplot(model.NoInteraction, aes(x = .fitted, y = .resid)) +
  geom_point() + 
  geom_hline(yintercept = 0)+
  labs(title = paste("Fitted-Value Plot for model.NoInteraction"), x = "Fitted Values", y = "Residuals") +
  theme(plot.title = element_text(hjust = 0.5)) 

# QQ plots - model.NoInteraction
ggplot(model.NoInteraction, aes(sample = .resid)) +
  stat_qq() +
  stat_qq_line()+
  labs(title = "Normal Q-Q Plot for NoInteraction", x = "Theoretical", y = "Sample") +
   theme(plot.title = element_text(hjust = 0.5)) 
```

There still appears to be a normality violation in the QQ plot. So, I need to compare the robust and non-robust models to make sure I do not need to worry about this violation.

```{r}
# Data to model
data_modified_ind <- ind_data %>%
  select(timeRemaining_ind,
         Target, 
         SessionOrder, 
         Team, 
         Player_ID) %>%
  mutate(sqrt.value = sqrt(ifelse(.data[["timeRemaining_ind"]] < 0, 0, .data[["timeRemaining_ind"]]))) # Some fo the time remaining vaules are negative when the should be zero. I want to make sure those values are zero

response_variable <- "sqrt.value"
data_focus_ind <- data_modified_ind

# Generate models with variable response
model.NoInteraction <- model_data_Target_Session(df = data_focus_ind, dependent =  response_variable, model.type =  "NoInteraction", is.team = FALSE, is.robust = FALSE)
rmodel.NoInteraction <- model_data_Target_Session(df = data_focus_ind, dependent =  response_variable, model.type =  "NoInteraction", is.team = FALSE, is.robust = TRUE)

compare(model.NoInteraction, rmodel.NoInteraction, show.rho.functions = FALSE) %>%
  kable() %>%
  kable_styling()
```

Comparing the robust and non-robust model does not reveal any concerning difference in estimated value.

*Reflection:* After the transformation, there still appeared to be a violation in the QQ plot but comparing the robust model to the non-robust model showed no concerning differences.

##### Q: Are there any effects that are significant?

```{r}
# Data to model
data_modified_ind <- ind_data %>%
  select(timeRemaining_ind,
         Target, 
         SessionOrder, 
         Team, 
         Player_ID) %>%
  mutate(sqrt.value = sqrt(ifelse(.data[["timeRemaining_ind"]] < 0, 0, .data[["timeRemaining_ind"]]))) # Some fo the time remaining vaules are negative when the should be zero. I want to make sure those values are zero

response_variable <- "sqrt.value"
data_focus_ind <- data_modified_ind

# Generate models with variable response
model.NoInteraction.NoTarget <- model_data_Target_Session(df = data_focus_ind, dependent =  response_variable, model.type =  "NoInteraction_NoTarget", is.team = FALSE, is.robust = FALSE)

# Histogram of Residuals - model.NoInteraction
ggplot(model.NoInteraction.NoTarget, aes(x = .resid)) +
  geom_histogram(bins = 30) + 
  labs(title = paste("Histogram of Residuals for model.NoInteraction"), x = "", y = "") +
  theme(plot.title = element_text(hjust = 0.5))

# Fitted values - model.NoInteraction
ggplot(model.NoInteraction.NoTarget, aes(x = .fitted, y = .resid)) +
  geom_point() + 
  geom_hline(yintercept = 0)+
  labs(title = paste("Fitted-Value Plot for model.NoInteraction"), x = "Fitted Values", y = "Residuals") +
  theme(plot.title = element_text(hjust = 0.5)) 

# QQ plots - model.NoInteraction
ggplot(model.NoInteraction.NoTarget, aes(sample = .resid)) +
  stat_qq() +
  stat_qq_line()+
  labs(title = "Normal Q-Q Plot for NoInteraction", x = "Theoretical", y = "Sample") +
   theme(plot.title = element_text(hjust = 0.5))  
```

The results showed a significant effect from session 3 and 4 when compared to session 2. This significant effect is expected. The results showed no significant impact from Target levels when compared to the Ind level. However, it is important to note that the effect from the Team Target level is approaching significance (p = .0779). This suggests that more data is needed to reach significance. 

```{r}
# Data to model
data_modified_ind <- ind_data %>%
  select(timeRemaining_ind,
         Target, 
         SessionOrder, 
         Team, 
         Player_ID) %>%
  mutate(sqrt.value = sqrt(ifelse(.data[["timeRemaining_ind"]] < 0, 0, .data[["timeRemaining_ind"]]))) # Some fo the time remaining vaules are negative when the should be zero. I want to make sure those values are zero

response_variable <- "sqrt.value"
data_focus_ind <- data_modified_ind

# Generate models with variable response
model.NoInteraction <- model_data_Target_Session(df = data_focus_ind, dependent =  response_variable, model.type =  "NoInteraction", is.team = FALSE, is.robust = FALSE)

emmeans(model.NoInteraction, list(pairwise ~ Target), adjust = "tukey")
```
The results show a *significant difference* between the Ind_Team and Team level of feedback. The difference indicates that the amount of time remaining in the Team feedback condition results in higher time remaining (transformed using 1/2 power). 

```{r}
# Data to model
data_modified_ind <- ind_data %>%
  select(timeRemaining_ind,
         Target, 
         SessionOrder, 
         Team, 
         Player_ID) %>%
  mutate(sqrt.value = sqrt(ifelse(.data[["timeRemaining_ind"]] < 0, 0, .data[["timeRemaining_ind"]]))) # Some fo the time remaining vaules are negative when the should be zero. I want to make sure those values are zero

response_variable <- "sqrt.value"
data_focus_ind <- data_modified_ind

# Generate models with variable response
model.NoInteraction <- model_data_Target_Session(df = data_focus_ind, dependent =  response_variable, model.type =  "NoInteraction", is.team = FALSE, is.robust = FALSE)

summary(model.NoInteraction)
```

There is a significant difference between each of the sessions. This result means that the time remaining at the end of the session was increasing over time. This increase in time remaining suggests that the teams were moving through the session faster the more times they completed the task (Note: This is when the data is transformed using the 1/2 power).

##### Summary / Reflection
         SessionOrder, 
         Team, 
         Player_ID) %>%
  mutate(sqrt.value = sqrt(ifelse(.data[["timeRemaining_ind"]] < 0, 0, .data[["timeRemaining_ind"]]))) # Some fo the time remaining vaules are negative when the should be zero. I want to make sure those values are zero

response_variable <- "sqrt.value"
data_focus_ind <- data_modified_ind

# Generate models with variable response
model.NoInteraction <- model_data_Target_Session(df = data_focus_ind, dependent =  response_variable, model.type =  "NoInteraction", is.team = FALSE, is.robust = FALSE)

emmeans(model.NoInteraction, list(pairwise ~ Target), adjust = "tukey")
```
The results show a *significant difference* between the Ind_Team and Team level of feedback. The difference indicates that the amount of time remaining in the Team feedback condition results in higher time remaining (transformed using 1/2 power). 

```{r}
# Data to model
data_modified_ind <- ind_data %>%
  select(timeRemaining_ind,
         Target, 
         SessionOrder, 
         Team, 
         Player_ID) %>%
  mutate(sqrt.value = sqrt(ifelse(.data[["timeRemaining_ind"]] < 0, 0, .data[["timeRemaining_ind"]]))) # Some fo the time remaining vaules are negative when the should be zero. I want to make sure those values are zero

response_variable <- "sqrt.value"
data_focus_ind <- data_modified_ind

# Generate models with variable response
model.NoInteraction <- model_data_Target_Session(df = data_focus_ind, dependent =  response_variable, model.type =  "NoInteraction", is.team = FALSE, is.robust = FALSE)

emmeans(model.NoInteraction, list(pairwise ~ SessionOrder), adjust = "tukey")
```

There is a significant different between each of the sessions. This means that the square root of the time remaining at the end of the session was increasing over time. This means that the teams were moving through the session faster the more they completed the task (Note: This is when the data is transformed using the 1/2 power).


Note: It is important to remember that a high performing team would have a lower collection rate.

#### Team

```{r}
# Data to model
data_modified_ind <- ind_data %>%
  select(timeRemaining_ind,
         Target, 
         SessionOrder, 
         Team, 
         Player_ID) %>%
  mutate(sqrt.value = sqrt(ifelse(.data[["timeRemaining_ind"]] < 0, 0, .data[["timeRemaining_ind"]]))) # Some fo the time remaining vaules are negative when the should be zero. I want to make sure those values are zero

response_variable <- "sqrt.value"
data_focus_ind <- data_modified_ind

# Generate models with variable response
model.NoInteraction.NoTarget <- model_data_Target_Session(df = data_focus_ind, dependent =  response_variable, model.type =  "NoInteraction_NoTarget", is.team = FALSE, is.robust = FALSE)

summary(model.NoInteraction.NoTarget)
```

The distribution tells me that most groups had a correct item collection rate of about 20 sec per correct item. In other words, group generally needed about 20 secs to collect a correct items. 

```{r}
# Data to model
data_modified_ind <- ind_data %>%
  select(timeRemaining_ind,
         Target, 
         SessionOrder, 
         Team, 
         Player_ID) %>%
  mutate(sqrt.value = sqrt(ifelse(.data[["timeRemaining_ind"]] < 0, 0, .data[["timeRemaining_ind"]]))) # Some fo the time remaining vaules are negative when the should be zero. I want to make sure those values are zero

response_variable <- "sqrt.value"
data_focus_ind <- data_modified_ind

# Generate models with variable response
model.NoInteraction.NoTarget <- model_data_Target_Session(df = data_focus_ind, dependent =  response_variable, model.type =  "NoInteraction_NoTarget", is.team = FALSE, is.robust = FALSE)

emmeans(model.NoInteraction.NoTarget, list(pairwise ~ SessionOrder), adjust = "tukey")
```

There is a significant difference between each of the sessions. This means that the amount of time (square root) remaining increased over time. 

##### Summary / Reflection

There was a significant difference between the Ind_Team and Team level feedback condition in the *model.NoInteraction*. The significant difference indicates that the amount of time remaining at the end of the session in the Team feedback condition is higher than the amount of time remaining in the Ind_Team condition. 

According to the data, groups should be given feedback that has team content if the goal is to encourage the team to move through the task faster. This does not tell me if the groups in the team condition are accurate as fast or if the groups are simply moving through the session quicker in the Team condition. 

The next step is to explore how groups collected items. In other words, I want to determine if the teams were collecting correct items quicker. 





# References
